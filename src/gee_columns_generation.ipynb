{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYljfrMBwslv"
   },
   "source": [
    "**Introduction**\n",
    "Generating the Extra Columns wiith earth Engine API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "VFCs7UizgEfC",
    "outputId": "2b6771b4-2ad6-4d89-b5b3-e5b45c78c620"
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import geemap\n",
    "import ee\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "\n",
    "# from google.colab import auth , drive\n",
    "# drive.mount('/content/drive') Only required if you are using google colab\n",
    "\n",
    "from helper_functions import calculate_area, calculate_built_area, calculate_road_length, calculate_forest_loss\n",
    "from helper_functions import calculate_elevation_and_slope, process_month, get_shadow_index_for_month, get_ndvi_for_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "lYlQ3kCMXlXV",
    "outputId": "6e070639-84b4-4dd6-cffc-6f77604517ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 1072466 entries, 0 to 1072465\n",
      "Data columns (total 17 columns):\n",
      " #   Column                        Non-Null Count    Dtype   \n",
      "---  ------                        --------------    -----   \n",
      " 0   site_id_created               1072466 non-null  int64   \n",
      " 1   project_id_reported           1072466 non-null  object  \n",
      " 2   site_id_reported              1072466 non-null  object  \n",
      " 3   site_description_reported     1682 non-null     object  \n",
      " 4   site_sqkm                     1072466 non-null  float64 \n",
      " 5   trees_planted_reported        4239 non-null     float64 \n",
      " 6   country                       4878 non-null     object  \n",
      " 7   project_description_reported  1071904 non-null  object  \n",
      " 8   planting_date_reported        1059586 non-null  float64 \n",
      " 9   survival_rate_reported        2374 non-null     float64 \n",
      " 10  host_name                     1072466 non-null  object  \n",
      " 11  url                           1072466 non-null  object  \n",
      " 12  species_count_reported        0 non-null        object  \n",
      " 13  species_planted_reported      116 non-null      object  \n",
      " 14  geometry                      1072465 non-null  geometry\n",
      " 15  Creator                       94 non-null       object  \n",
      " 16  project_id_created            1072466 non-null  int64   \n",
      "dtypes: float64(4), geometry(1), int64(2), object(10)\n",
      "memory usage: 139.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df = gpd.read_parquet(\"../midsave/consolidated_reforestation_projects.parquet\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gdf = df.loc[:,['site_id_created', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gdf.dropna(subset=['geometry'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a subsample for testing code ! Delete when done !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gdf = df.loc[0:10000, ['site_id_created', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gdf.dropna(subset=['geometry'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticate with Google Earth Engine\n",
    "Need to log in to EarthEngine (ee.Authenticate()), create a project and then initialize this project via ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/cloud-platform%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=n36eoMHnGTp0POgjtUejuErE0vyFq6ENsuyENktd85c&tc=t9ABGtBNKxTYhu-EMM7-UTfRnaK2cTQNq33ekweyQ7U&cc=1PoExGroO_xzH4e2poe_WUA8uzfvGnJHvnu8bW5Yk6E>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/cloud-platform%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=n36eoMHnGTp0POgjtUejuErE0vyFq6ENsuyENktd85c&tc=t9ABGtBNKxTYhu-EMM7-UTfRnaK2cTQNq33ekweyQ7U&cc=1PoExGroO_xzH4e2poe_WUA8uzfvGnJHvnu8bW5Yk6E</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter verification code:  4/1AeanS0aRPnFFB1oLvpQhSZ5xsTG3vyqOxeXZR--YU1Xoz-iPWX94CRf9ZIw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*** Earth Engine *** Share your feedback by taking our Annual Developer Satisfaction Survey: https://google.qualtrics.com/jfe/form/SV_0JLhFqfSY1uiEaW?source=Init\n"
     ]
    }
   ],
   "source": [
    "ee.Initialize(project='test-reforestation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "vXiObiAgxscR",
    "outputId": "afc4ca4e-e2be-403b-8fc8-4b2ff6cd57df"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ee.Initialize(project='spring-idiom-398208')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnbpOL6EbmK4"
   },
   "source": [
    "### Calculating Tree Cover\n",
    "- tree_cover_area_2000\n",
    "- tree_cover_area_2005\n",
    "- tree_cover_area_2010\n",
    "- tree_cover_area_2015\n",
    "- tree_cover_area_2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chunk_size = 1000\n",
    "chunks = [gdf[i:i + chunk_size] for i in range(0, gdf.shape[0], chunk_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GLAD Landcover (https://glad.umd.edu/dataset/GLCLUC2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "landmask = ee.Image(\"projects/glad/OceanMask\").lte(1)\n",
    "landCover = ee.Image('projects/glad/GLCLU2020/v2/LCLUC_2020').updateMask(landmask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masking land cover image to only include class codes of interest for tree cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classCodes = [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48,\n",
    "              125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148]\n",
    "maskedLandCover = landCover.remap(classCodes, classCodes, 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating area for each class list in the codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_csv_path = '../midsave/tree_cover.csv'\n",
    "tree_cover = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "bwlZmsIgbaFh",
    "outputId": "3c26595c-6026-40ab-938a-f843bab0f63e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1/10\n"
     ]
    },
    {
     "ename": "EEException",
     "evalue": "GeometryConstructors.MultiGeometry: Geometry coordinate projection requires non-zero maxError.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ee/data.py:406\u001b[0m, in \u001b[0;36m_execute_cloud_call\u001b[0;34m(call, num_retries)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 406\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m call\u001b[38;5;241m.\u001b[39mexecute(num_retries\u001b[38;5;241m=\u001b[39mnum_retries)\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m googleapiclient\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mHttpError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/googleapiclient/_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/googleapiclient/http.py:938\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpError(resp, content, uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muri)\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostproc(resp, content)\n",
      "\u001b[0;31mHttpError\u001b[0m: <HttpError 400 when requesting https://earthengine.googleapis.com/v1/projects/test-reforestation/value:compute?prettyPrint=false&alt=json returned \"GeometryConstructors.MultiGeometry: Geometry coordinate projection requires non-zero maxError.\". Details: \"GeometryConstructors.MultiGeometry: Geometry coordinate projection requires non-zero maxError.\">",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEEException\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Mapping the area calculation function over the FeatureCollection\u001b[39;00m\n\u001b[1;32m     15\u001b[0m area_results_chunk \u001b[38;5;241m=\u001b[39m fc_chunk\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m feature: calculate_area(feature, classCodes, maskedLandCover))\n\u001b[0;32m---> 16\u001b[0m temp_chunk_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([feature[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m area_results_chunk\u001b[38;5;241m.\u001b[39mgetInfo()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m     17\u001b[0m temp_chunk_df\u001b[38;5;241m.\u001b[39mrename(columns \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcover_area_2020\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtree_cover_area_2020\u001b[39m\u001b[38;5;124m'\u001b[39m}, inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Appending to combined DataFrame\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ee/collection.py:560\u001b[0m, in \u001b[0;36mCollection.getInfo\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetInfo\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Any]:\n\u001b[1;32m    548\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns all the known information about this collection.\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \n\u001b[1;32m    550\u001b[0m \u001b[38;5;124;03m  This function makes a REST call to to retrieve all the known information\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;124;03m         properties.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 560\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetInfo()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ee/computedobject.py:107\u001b[0m, in \u001b[0;36mComputedObject.getInfo\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetInfo\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Any]:\n\u001b[1;32m    102\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Fetch and return information about this object.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m  Returns:\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    The object can evaluate to anything.\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcomputeValue(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ee/data.py:1126\u001b[0m, in \u001b[0;36mcomputeValue\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1123\u001b[0m body \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpression\u001b[39m\u001b[38;5;124m'\u001b[39m: serializer\u001b[38;5;241m.\u001b[39mencode(obj, for_cloud_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)}\n\u001b[1;32m   1124\u001b[0m _maybe_populate_workload_tag(body)\n\u001b[0;32m-> 1126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _execute_cloud_call(\n\u001b[1;32m   1127\u001b[0m     _get_cloud_projects()\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;241m.\u001b[39mvalue()\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;241m.\u001b[39mcompute(body\u001b[38;5;241m=\u001b[39mbody, project\u001b[38;5;241m=\u001b[39m_get_projects_path(), prettyPrint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1130\u001b[0m )[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ee/data.py:408\u001b[0m, in \u001b[0;36m_execute_cloud_call\u001b[0;34m(call, num_retries)\u001b[0m\n\u001b[1;32m    406\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m call\u001b[38;5;241m.\u001b[39mexecute(num_retries\u001b[38;5;241m=\u001b[39mnum_retries)\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m googleapiclient\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mHttpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 408\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m _translate_cloud_exception(e)\n",
      "\u001b[0;31mEEException\u001b[0m: GeometryConstructors.MultiGeometry: Geometry coordinate projection requires non-zero maxError."
     ]
    }
   ],
   "source": [
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Processing chunk {i + 1}/{len(chunks)}\")\n",
    "\n",
    "    # Converting GeoDataFrame chunk to GeoJSON and then Earth Engine FeatureCollection\n",
    "    gdf_json_chunk = chunk.__geo_interface__\n",
    "    \n",
    "    try:\n",
    "        # Converting to Earth Engine FeatureCollection\n",
    "        fc_chunk = geemap.geojson_to_ee(gdf_json_chunk)\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting chunk {i + 1} to Earth Engine FeatureCollection: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Mapping the area calculation function over the FeatureCollection\n",
    "    area_results_chunk = fc_chunk.map(lambda feature: calculate_area(feature, classCodes, maskedLandCover))\n",
    "    temp_chunk_df = pd.DataFrame([feature['properties'] for feature in area_results_chunk.getInfo()['features']])\n",
    "    temp_chunk_df.rename(columns = {'cover_area_2020':'tree_cover_area_2020'}, inplace = True)\n",
    "    # Appending to combined DataFrame\n",
    "    tree_cover = pd.concat([tree_cover, temp_chunk_df], ignore_index=True)\n",
    "\n",
    "    # Saving combined results to the output CSV\n",
    "    tree_cover.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(\"All chunks processed, combined results saved to:\", output_csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9bzuuIzb7E-"
   },
   "source": [
    "### Calculating other land cover\n",
    "- permanent_water\n",
    "- short_vegetation_after_tree_loss\n",
    "- cropland_loss_to_tree\n",
    "- cropland_gain_from_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classCodes = [208, 240, 248, 245]\n",
    "classesOfInterest = [\"permanent_water\", \"short_vegetation_after_tree_loss\", \"cropland_loss_to_tree\", \"cropland_gain_from_trees\"]\n",
    "maskedLandCover = landCover.remap(classCodes, classCodes, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv_path = '../midsave/other_land_cover.csv'\n",
    "other_land_cover = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Processing chunk {i + 1}/{len(chunks)}\")\n",
    "\n",
    "    # Converting GeoDataFrame chunk to GeoJSON and then Earth Engine FeatureCollection\n",
    "    gdf_json_chunk = chunk.__geo_interface__\n",
    "    \n",
    "    try:\n",
    "        # Converting to Earth Engine FeatureCollection\n",
    "        fc_chunk = geemap.geojson_to_ee(gdf_json_chunk)\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting chunk {i + 1} to Earth Engine FeatureCollection: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Mapping the area calculation function over the FeatureCollection\n",
    "    area_results_chunk = fc_chunk.map(lambda feature: calculate_area(feature, classCodes, maskedLandCover))\n",
    "    if area_results_chunk:\n",
    "        temp_chunk_df = pd.DataFrame([feature['properties'] for feature in area_results_chunk.getInfo()['features']])\n",
    "        temp_chunk_df.rename(columns = {'cover_area_2020':'other_land_cover_area_2020'}, inplace = True)\n",
    "    else:\n",
    "        temp_chunk_df = pd.DataFrame()\n",
    "\n",
    "    other_land_cover = pd.concat([other_land_cover, temp_chunk_df], ignore_index=True)\n",
    "\n",
    "    other_land_cover.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(\"All chunks processed, combined results saved to:\", output_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IGtZpPxwuY5x"
   },
   "source": [
    "### Calculate built-area shares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Earth Engine built area image for 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builtImage = ee.Image(\"JRC/GHSL/P2023A/GHS_BUILT_C/2018\").select('built_characteristics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv_path = '../midsave/built_area_cover.csv'\n",
    "built_area_cover = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Processing built area for chunk {i + 1}/{len(chunks)}\")\n",
    "\n",
    "    # Converting GeoDataFrame chunk to GeoJSON and then Earth Engine FeatureCollection\n",
    "    gdf_json_chunk = chunk.__geo_interface__\n",
    "\n",
    "    try:\n",
    "        # Converting the GeoJSON chunk to Earth Engine FeatureCollection\n",
    "        fc_chunk = geemap.geojson_to_ee(gdf_json_chunk)\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting chunk {i + 1} to Earth Engine FeatureCollection: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Mapping the built area calculation function over the FeatureCollection\n",
    "    built_area_results_chunk = fc_chunk.map(lambda feature: calculate_built_area(feature, builtImage))\n",
    "    if built_area_results_chunk:\n",
    "        temp_chunk_df = pd.DataFrame([feature['properties'] for feature in built_area_results_chunk.getInfo()['features']])\n",
    "    else:\n",
    "        temp_chunk_df = pd.DataFrame()\n",
    "\n",
    "    built_area_cover = pd.concat([built_area_cover, temp_chunk_df], ignore_index=True)\n",
    "\n",
    "    built_area_cover.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(\"All chunks processed, built area results saved to:\", output_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-oBg_Hhuhcy"
   },
   "source": [
    "### Calculating road network cover\n",
    "- total_road_length_km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging GEE road datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roadsAfrica = ee.FeatureCollection('projects/ee-forest-monitoring/assets/gROADS-v1-africa')\n",
    "roadsAmericas = ee.FeatureCollection('projects/ee-forest-monitoring/assets/gROADS-v1-americas')\n",
    "roadsAsia = ee.FeatureCollection('projects/ee-forest-monitoring/assets/gROADS-v1-asia')\n",
    "roadsEurope = ee.FeatureCollection('projects/ee-forest-monitoring/assets/gROADS-v1-europe')\n",
    "roadsOceaniaEast = ee.FeatureCollection('projects/ee-forest-monitoring/assets/gROADS-v1-oceania-east')\n",
    "roadsOceaniaWest = ee.FeatureCollection('projects/ee-forest-monitoring/assets/gROADS-v1-oceania-west')\n",
    "\n",
    "roads = roadsAfrica.merge(roadsAmericas).merge(roadsAsia).merge(roadsEurope).merge(roadsOceaniaEast).merge(roadsOceaniaWest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv_path = '../midsave/road_length.csv'\n",
    "road_length = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Processing road length for chunk {i + 1}/{len(chunks)}\")\n",
    "\n",
    "    gdf_json_chunk = chunk.__geo_interface__\n",
    "\n",
    "    try:\n",
    "        # Converting the GeoJSON chunk to Earth Engine FeatureCollection\n",
    "        fc_chunk = geemap.geojson_to_ee(gdf_json_chunk)\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting chunk {i + 1} to Earth Engine FeatureCollection: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Mapping the road length calculation function over the FeatureCollection\n",
    "    road_length_results_chunk = fc_chunk.map(lambda feature: calculate_road_length(feature, roads))\n",
    "    if road_length_results_chunk:\n",
    "        temp_chunk_df = pd.DataFrame([feature['properties'] for feature in road_length_results_chunk.getInfo()['features']])\n",
    "    else:\n",
    "        temp_chunk_df = pd.DataFrame()\n",
    "\n",
    "    road_length = pd.concat([road_length, temp_chunk_df], ignore_index=True)\n",
    "\n",
    "    road_length.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(\"All chunks processed, road length results saved to:\", output_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCScIwE2vgn_"
   },
   "source": [
    "### Calculating forest loss\n",
    "- loss_pre_5\n",
    "- loss_post_3\n",
    "- loss_post_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Global Forest Change 2023 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfc2017 = ee.Image('UMD/hansen/global_forest_change_2023_v1_11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv_path = '../midsave/forest_loss.csv'\n",
    "forest_loss = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Processing forest loss for chunk {i + 1}/{len(chunks)}\")\n",
    "\n",
    "    # Converting the current GeoDataFrame chunk to GeoJSON\n",
    "    gdf_json_chunk = chunk.__geo_interface__\n",
    "\n",
    "    try:\n",
    "        # Converting GeoJSON chunk to Earth Engine FeatureCollection\n",
    "        fc_chunk = geemap.geojson_to_ee(gdf_json_chunk)\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting chunk {i + 1} to Earth Engine FeatureCollection: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Mapping the forest loss calculation function over the FeatureCollection\n",
    "    loss_results_chunk = fc_chunk.map(lambda feature: calculate_forest_loss(feature, gfc2017))\n",
    "    if loss_results_chunk:\n",
    "        temp_chunk_df = pd.DataFrame([feature['properties'] for feature in loss_results_chunk.getInfo()['features']])\n",
    "    else:\n",
    "        temp_chunk_df = pd.DataFrame()\n",
    "\n",
    "    forest_loss = pd.concat([forest_loss, temp_chunk_df], ignore_index=True)\n",
    "\n",
    "print(\"All chunks processed, forest loss results saved to:\", output_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWy6FPvg_Tdp"
   },
   "source": [
    "#### Generating the loss columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = (forest_loss['groups']\n",
    "               .explode()\n",
    "               .dropna()\n",
    "               .reset_index()\n",
    "               .rename(columns = {'index':'site_id_created'})\n",
    "               .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = (pd.json_normalize(temp['groups']).reset_index()\n",
    "               .merge(temp[['index','site_id_created']], on = 'index', how = 'left').drop(columns = ['index']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['year'] = 2000 + temp['group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_loss = temp.pivot(index=['site_id_created'], columns='year', values='sum')\n",
    "forest_loss.columns = [col for col in forest_loss.columns]\n",
    "#forest_loss.columns = [f'forest_loss_{col}' for col in forest_loss.columns]\n",
    "forest_loss.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add planting date information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_loss = forest_loss.merge(df[['site_id_created','planting_date_reported']], on = 'site_id_created', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k-g1u3I6AOfn"
   },
   "outputs": [],
   "source": [
    "def calculate_loss_pre_5(row):\n",
    "    try:\n",
    "        years = [int(row['planting_date_reported'] - i) for i in range(1, 6)]\n",
    "        losses = [row[year] for year in years if year in forest_loss.columns]\n",
    "        return np.nanmean(losses) if losses else np.nan\n",
    "    except Exception as e:\n",
    "        return np.nan\n",
    "\n",
    "def calculate_loss_post_3(row):\n",
    "    try:\n",
    "        years = [int(row['planting_date_reported'] + i) for i in range(1, 4)]\n",
    "        losses = [row[year] for year in years if year in forest_loss.columns]\n",
    "        return np.nanmean(losses) if losses else np.nan\n",
    "    except Exception as e:\n",
    "        return np.nan\n",
    "\n",
    "def calculate_loss_post_5(row):\n",
    "    try:\n",
    "        years = [int(row['planting_date_reported'] + i) for i in range(1, 6)]\n",
    "        losses = [row[year] for year in years if year in forest_loss.columns]\n",
    "        return np.nanmean(losses) if losses else np.nan\n",
    "    except Exception as e:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "forest_loss['loss_pre_5'] = forest_loss.apply(calculate_loss_pre_5, axis=1)\n",
    "forest_loss['loss_post_3'] = forest_loss.apply(calculate_loss_post_3, axis=1)\n",
    "forest_loss['loss_post_5'] = forest_loss.apply(calculate_loss_post_5, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_loss.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "id": "un1PPqdmATx_",
    "outputId": "75c811ee-6ed2-411a-f6b6-abcef49d09f2"
   },
   "outputs": [],
   "source": [
    "forest_loss.drop(columns = [year for year in range(2000, 2024)] + ['planting_date_reported'], errors = 'ignore', inplace = True)\n",
    "forest_loss.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_loss.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating elevation and slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Digital Elevations Model (DEM) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ee.Image('USGS/SRTMGL1_003')\n",
    "elevation = dataset.select('elevation')\n",
    "slope = ee.Terrain.slope(elevation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv_path = '../midsave/elevation_slope.csv'\n",
    "elevation_slope = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Processing chunk {i + 1}/{len(chunks)}\")\n",
    "\n",
    "    # Converting GeoDataFrame chunk to GeoJSON and then to Earth Engine FeatureCollection\n",
    "    gdf_json_chunk = chunk.__geo_interface__\n",
    "\n",
    "    try:\n",
    "        fc_chunk = geemap.geojson_to_ee(gdf_json_chunk)\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting chunk {i + 1} to Earth Engine FeatureCollection: {e}\")\n",
    "        continue\n",
    "\n",
    "    results_chunk = fc_chunk.map(lambda feature: calculate_elevation_and_slope(feature, elevation, slope))\n",
    "    if results_chunk:\n",
    "        temp_chunk_df = pd.DataFrame([feature['properties'] for feature in results_chunk.getInfo()['features']])\n",
    "    else:\n",
    "        temp_chunk_df = pd.DataFrame()\n",
    "\n",
    "    # Appending to combined DataFrame\n",
    "    elevation_slope = pd.concat([elevation_slope, temp_chunk_df], ignore_index=True)\n",
    "\n",
    "    elevation_slope.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(\"All chunks processed, combined results saved to:\", output_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbUqO4WBwLIS"
   },
   "source": [
    "### Calculate NDVI per month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Sentinel-2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S2 = ee.ImageCollection('COPERNICUS/S2_HARMONIZED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv_path = '../midsave/ndvi_top3.csv'\n",
    "ndvi_monthly = pd.DataFrame()\n",
    "months = range(1, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while months:\n",
    "    try:\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            futures = {executor.submit(process_month, month, chunks, S2): month for month in months}\n",
    "            \n",
    "            for future in tqdm(concurrent.futures.as_completed(futures), total=len(months)):\n",
    "                month_result = future.result()\n",
    "                ndvi_monthly = pd.concat([ndvi_monthly, month_result], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        months = list(set(months) - set(ndvi_monthly.month.unique().tolist()))\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select three months with the highest NDVI values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_top3 = (ndvi_monthly\n",
    "             .groupby('site_id_created', group_keys=False)[['site_id_created', 'month', 'mean']]\n",
    "             .apply(lambda x: x.nlargest(3, 'mean'))\n",
    "             .rename(columns = {'mean':'ndvi_monthly_mean'})\n",
    "             .reset_index(drop = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1V6MQ6bIDJV-"
   },
   "outputs": [],
   "source": [
    "ndvi_top3.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shadow Index "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before shadow index ensure Top_Three_NDVI_Months and planting dates are added to df data (After creating the column Top_Three_Ndvi_months rerun cell 5 where chunks are processed to update and include the column in the chunk before running the Shadow index cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_si = (gdf\n",
    "       .merge(df[['site_id_created', 'planting_date_reported']], on = 'site_id_created', how = 'left')\n",
    "       .merge(ndvi_top3[['site_id_created', 'month', 'ndvi_monthly_mean']], on = 'site_id_created', how = 'left')\n",
    "       .dropna()\n",
    "       .reset_index(drop = True))\n",
    "gdf_si['planting_date_reported'] = gdf_si['planting_date_reported'].astype(int)\n",
    "gdf_si['month'] = gdf_si['month'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 1000\n",
    "chunks = [gdf_si[i:i + chunk_size] for i in range(0, gdf_si.shape[0], chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv_path = '../midsave/shadow_index.csv'\n",
    "shadow_index = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, chunk in enumerate(chunks):\n",
    "        print(f\"Processing chunk {i + 1}/{len(chunks)}\")\n",
    "\n",
    "        gdf_json_chunk = chunk.__geo_interface__\n",
    "\n",
    "        try:\n",
    "            fc_chunk = geemap.geojson_to_ee(gdf_json_chunk)\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting chunk {i + 1} to Earth Engine FeatureCollection: {e}\")\n",
    "            continue\n",
    "        shadow_index_chunk = fc_chunk.map(lambda feature: get_shadow_index_for_month(feature, S2))\n",
    "\n",
    "        if results_chunk:\n",
    "            temp_chunk_df = pd.DataFrame([feature['properties'] for feature in shadow_index_chunk.getInfo()['features']])\n",
    "        else:\n",
    "            temp_chunk_df = pd.DataFrame()\n",
    "        \n",
    "        # Appending to combined DataFrame\n",
    "        shadow_index = pd.concat([shadow_index, temp_chunk_df], ignore_index=True)\n",
    "\n",
    "shadow_index_grouped = shadow_index.groupby(['site_id_created'])['shadow_index'].mean().reset_index()\n",
    "shadow_index_grouped.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(\"All chunks processed, combined results saved to:\", output_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_index_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NDVI\n",
    "- atplanting\n",
    "- 1 year after planting\n",
    "- 2 years after planting\n",
    "- 5 years after planting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv_path = '../midsave/ndvi.csv'\n",
    "ndvi = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, chunk in enumerate(chunks):\n",
    "        print(f\"Processing chunk {i + 1}/{len(chunks)}\")\n",
    "\n",
    "        gdf_json_chunk = chunk.__geo_interface__\n",
    "\n",
    "        try:\n",
    "            fc_chunk = geemap.geojson_to_ee(gdf_json_chunk)\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting chunk {i + 1} to Earth Engine FeatureCollection: {e}\")\n",
    "            continue\n",
    "        ndvi_chunk = fc_chunk.map(lambda feature: get_ndvi_for_month(feature, S2))\n",
    "\n",
    "        if results_chunk:\n",
    "            temp_chunk_df = pd.DataFrame([feature['properties'] for feature in ndvi_chunk.getInfo()['features']])\n",
    "        else:\n",
    "            temp_chunk_df = pd.DataFrame()\n",
    "        \n",
    "        # Appending to combined DataFrame\n",
    "        ndvi = pd.concat([ndvi, temp_chunk_df], ignore_index=True)\n",
    "\n",
    "ndvi_grouped = ndvi.groupby(['site_id_created'])['ndvi'].mean().reset_index()\n",
    "ndvi_grouped.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(\"All chunks processed, combined results saved to:\", output_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = (df\n",
    "               .merge(tree_cover, on = 'site_id_created', how = 'left')\n",
    "               .merge(other_land_cover, on = 'site_id_created', how = 'left')\n",
    "               .merge(built_area_cover, on = 'site_id_created', how = 'left')\n",
    "               .merge(road_length, on = 'site_id_created', how = 'left')\n",
    "               .merge(forest_loss, on = 'site_id_created', how = 'left')\n",
    "               .merge(elevation_slope, on = 'site_id_created', how = 'left')\n",
    "               .merge(ndvi_top3, on = 'site_id_created', how = 'left')\n",
    "               .merge(shadow_index_grouped, on = 'site_id_created', how = 'left')\n",
    "               .merge(ndvi_grouped, on = 'site_id_created', how = 'left'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.info()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
