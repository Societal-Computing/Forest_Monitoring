{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape, Polygon, MultiPolygon\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "from helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Defining  longitude ranges (left to right) in 45-degree increments to extract the ids from the Restor website\n",
    "longitude_lefts = [-180 + i * 45 for i in range(8)]\n",
    "\n",
    "#Defining the latitude steps following the web mercator projection as the Restor website uses this projection\n",
    "latitude_steps = [\n",
    "    85.0511,  # The Maximum latitude in Web Mercator\n",
    "    79.17133464081945,\n",
    "    66.51326044311186,\n",
    "    40.97989806962013,\n",
    "    0,\n",
    "    -40.97989806962013,\n",
    "    -66.51326044311186,\n",
    "    -79.17133464081945,\n",
    "    -85.0511  # Minimum latitude in Web Mercator\n",
    "]\n",
    "\n",
    "# extracting all urls for the Restor website using the longitude and latitude stepsas per the restor website\n",
    "urls = []\n",
    "for left in longitude_lefts:\n",
    "    right = left + 45\n",
    "    for i in range(len(latitude_steps) - 1):\n",
    "        top = latitude_steps[i]\n",
    "        bottom = latitude_steps[i + 1]\n",
    "        if top > bottom:  \n",
    "            url = (\n",
    "                f\"https://restor2-prod-1-api.restor.eco/sites/3/center-points/\"\n",
    "                f\"?bottom={bottom}&left={left}&right={right}&top={top}&visibility=PUBLIC\"\n",
    "            )\n",
    "            urls.append(url)\n",
    "\n",
    "# Collecting all ids from all urls in the Restor website\n",
    "all_data = []\n",
    "\n",
    "for url in urls:\n",
    "    try:\n",
    "        response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        response.raise_for_status()  \n",
    "        data = response.json()\n",
    "        if isinstance(data, list):\n",
    "            all_data.extend(data)\n",
    "            print(f\"Fetched {len(data)} items from {url}\")\n",
    "        else:\n",
    "            print(f\"Unexpected data format from {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "    time.sleep(1)  \n",
    "\n",
    "# Saving all collected ids to a json file\n",
    "with open('../input/Restor_Eco/all_restor_data.json', 'w') as f:\n",
    "    json.dump(all_data, f, indent=2)\n",
    "\n",
    "print(f\"Data collection complete. Saved {len(all_data)} items to all_restor_data.json.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('../input/Restor_Eco/all_restor_data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for id in df['id']:\n",
    "    data = fetch_data(id)\n",
    "    if data is not None:\n",
    "        result_list.append(data)\n",
    "\n",
    "    time.sleep(1)  \n",
    "\n",
    "# Converting the list of dictionaries to DataFrame\n",
    "if result_list:\n",
    "    final_df = pd.DataFrame(result_list)\n",
    "    final_df.reset_index(drop=True, inplace=True)\n",
    "    print(final_df)\n",
    "\n",
    "    final_df.to_csv('../input/Restor_Eco/final_restor_data.csv', index=False)\n",
    "else:\n",
    "    print(\"No data was retrieved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_df[final_df[\"siteType\"] == \"RESTORATION\"]\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting string to dictionary\n",
    "df['polygon'] = df['polygon'].apply(ast.literal_eval)\n",
    "\n",
    "df['geometry'] = df['polygon'].apply(lambda x: shape(x) if isinstance(x, dict) else Polygon())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(df, geometry = 'geometry', crs = 'EPSG:4326')\n",
    "gdf['geometry'] = gdf['geometry'].make_valid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf.explode(index_parts = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf[(gdf.geometry.geom_type == 'Polygon') | (gdf.geometry.geom_type == 'MultiPolygon')]\n",
    "gdf = gdf.explode(index_parts = False)\n",
    "gdf = gdf.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Harmonize nomenclature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['site_sqkm'] = gdf['geometry'].to_crs(3857).area / 1e6\n",
    "gdf['site_sqkm'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['country'] = gdf['countryCode'].apply(lambda x: x if isinstance(x, str) else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the columns to follow our naming format in the paper columns section\n",
    "columns_rename_mapping = {\n",
    "    'id': 'project_id_reported',\n",
    "    'description': 'project_description_reported',\n",
    "    'interventionStartYear': 'planting_date_reported',\n",
    "    'website': 'url'\n",
    "}\n",
    "gdf.rename(columns=columns_rename_mapping, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[\"planting_date_reported\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['project_description_reported'] = gdf['project_description_reported'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else x)\n",
    "gdf['planting_date_reported'] = gdf['planting_date_reported'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else x)\n",
    "gdf['url'] = gdf['url'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\n",
    "     'project_id_reported',\n",
    "    'project_description_reported',\n",
    "     'planting_date_reported',\n",
    "     'geometry',\n",
    "     'url',\n",
    "     'site_sqkm',\n",
    "     'country'\n",
    "]\n",
    "gdf=gdf[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['planting_date_reported'] = gdf['planting_date_reported'].replace('', np.nan).astype(float)\n",
    "gdf['planting_date_reported'] = gdf['planting_date_reported'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['site_id_reported'] = ['restor_site_{}'.format(i) for i in range(1, len(gdf) + 1)]\n",
    "gdf ['host_name'] = 'Restor Eco'\n",
    "gdf['url'] = 'https://restor.eco/sites/' + gdf['project_id_reported'].astype(str)\n",
    "\n",
    "gdf = gdf.assign(species_count_reported=None, species_planted_reported=None, survival_rate_reported=None,trees_planted_reported=None)\n",
    "gdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_geom = False\n",
    "\n",
    "if len(gdf[gdf.geometry.is_valid == False]) > 0:\n",
    "    invalid_geom = True\n",
    "gdf['project_geometries_invalid'] = invalid_geom\n",
    "gdf[\"planting_date_type\"]=\"Intervention Start Year\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file('../midsave/restor_eco.gpkg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
