{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this script, we combine all the sites from the different reforestation projects from different organization to one dataset and do some initial filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely import wkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plant_planet_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We extracted the data from https://www.plant-for-the-planet.org as described in the script 'Plant_Planet_Meta_Data_preprocessing.ipynb'. Further, we already filtered the data in the script 'Plant_Planet_Meta_Data_preprocessing.ipynb',and upload the shape file generated in this script to the asset section of google earth enginee and then added some metadata to the files as more closely described in 'GEE_columns generation.ipynb' and harmonize the column naming as in the data description section of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plant = gpd.read_file(\"../input/Plant_for_planet_shapefiles/plant_planet.gpkg\")\n",
    "df_plant.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plant[\"geometry\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree_Nation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extracted and filtered  the data from https://tree-nation.com/projects as described in the script 'Tree_Nation-meta_data_pre.ipynb'.and upload the shape file of the resulting data to the asset section of google earth enginee and then added some metadata to the files as more closely described in 'GEE_columns generation.ipynb' and harmonize the column naming as in the data description section of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nation_2 =pd.read_csv(\"../input/Plant_for_planet_shapefiles/Tree_Nation.csv\",encoding='latin-1')\n",
    "df_nation_2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### For all others for additional data columns assimilation run the  script GEE_columns_generation.ipynb  with original metadata and ensure all columns naming are consistent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open_Forest_protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extracted and filtered  the data from https://atlas.openforestprotocol.org/  as described in the script  \"open_forest_projests_Data_filtering.ipynb\" and upload the shape file of the resulting data to the asset section of google earth enginee and then added some metadata to the files as more closely described in 'GEE_columns generation.ipynb' and harmonize the column naming as in the data description section of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atla_new=pd.read_csv(\"../input/Atlas/atlas_data.csv\")\n",
    "df_atla_new.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TIST data_with_trees_planted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extracted and filtered  the data from https://registry.verra.org/app/search/VCS as described in the script  \"Verra_Data_filtering.ipynb\" and upload the shape file of the resulting data to the asset section of google earth enginee and then added some metadata to the files as more closely described in 'GEE_columns generation.ipynb' and harmonize the column naming as in the data description section of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tist_2=pd.read_csv(\"../input/TIST/TIST_Meta.csv\",encoding='latin-1')\n",
    "df_tist_2['host_name'] = 'TIST'\n",
    "df_tist_2['url'] = 'https://program.tist.org'\n",
    "df_tist_2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TIST data_without_trees_planted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extracted and filtered  the data from https://registry.verra.org/app/search/VCS as described in the script  \"Verra_Data_filtering.ipynb\" and upload the shape file of the resulting data to the asset section of google earth enginee and then added some metadata to the files as more closely described in 'GEE_columns generation.ipynb' and harmonize the column naming as in the data description section of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tist_w_2=pd.read_csv(\"../input/TIST/TIST_Meta_without_trees.csv\",encoding='latin-1')\n",
    "df_tist_w_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tist_w_2['host_name'] = 'TIST'\n",
    "df_tist_w_2['url'] = 'https://program.tist.org'\n",
    "df_tist_w_2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ASIA_VERRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extracted and filtered  the data from https://registry.verra.org/app/search/VCS as described in the script  \"Verra_Data_filtering.ipynb\" and upload the shape file of the resulting data to the asset section of google earth enginee and then added some metadata to the files as more closely described in 'GEE_columns generation.ipynb' and harmonize the column naming as in the data description section of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asia_2=pd.read_csv(\"../input/Verra/Asia.csv\",encoding='latin-1')\n",
    "df_asia_2['host_name'] = 'VCS'\n",
    "df_asia_2['url'] = 'https://registry.verra.org/app/search/VCS'\n",
    "df_asia_2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VERRA Latin America"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extracted and filtered  the data from https://registry.verra.org/app/search/VCS as described in the script  \"Verra_Data_filtering.ipynb\" and upload the shape file of the resulting data to the asset section of google earth enginee and then added some metadata to the files as more closely described in 'GEE_columns generation.ipynb' and harmonize the column naming as in the data description section of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_latin_2=pd.read_csv(\"../input/Verra/latin.csv\",encoding='latin-1')\n",
    "df_latin_2['host_name'] = 'VCS'\n",
    "df_latin_2['url'] = 'https://registry.verra.org/app/search/VCS'\n",
    "df_latin_2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TIST other areas projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extracted and filtered  the data from https://registry.verra.org/app/search/VCS as described in the script  \"Verra_Data_filtering.ipynb\" and upload the shape file of the resulting data to the asset section of google earth enginee and then added some metadata to the files as more closely described in 'GEE_columns generation.ipynb' and harmonize the column naming as in the data description section of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_other_2=pd.read_csv(\"../input/Verra/OTHER_verra_projects.csv\",encoding='latin-1')\n",
    "df_other_2['host_name'] = 'VCS'\n",
    "df_other_2['url'] = 'https://registry.verra.org/app/search/VCS'\n",
    "df_other_2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restor eco data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extracted and filtered  the data from  https://restor.eco/?lat=10.743821093825016&lng=4.473759981496621&zoom=4 as described in the script  \"restor.ipynb\" and upload the shape file of the resulting data to the asset section of google earth enginee and then added some metadata to the files as more closely described in 'GEE_columns generation.ipynb' and harmonize the column naming as in the data description section of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eco_2=pd.read_csv(\"../input/Restor_Eco/restor_eco.csv\",encoding='latin-1')\n",
    "df_eco_2 ['host_name'] = 'Restor Eco'\n",
    "df_eco_2['url'] = 'https://restor.eco/?lat=26&lng=14.23&zoom=3'\n",
    "df_eco_2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explorer Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is extracted from te we forest projects website https://explorer.land/x/projects,the column names were manually edited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ex=pd.read_csv(\"../input/ExplorerLand/explorer_land.csv\")\n",
    "df_ex['host_name'] = 'Explorer Land'\n",
    "df_ex['url'] = 'https://explorer.land/x/projects'\n",
    "df_ex.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ex.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extracted  the data from  https://facethefuture.com/#projects described in the script 'Face_Future_metadata_prepro.ipynb'. Further, we already filtered the data in the script 'Face_Future_metadata_prepro.ipynb',and upload the shape file generated in this script to the asset section of google earth enginee and then added some metadata to the files as more closely described in 'GEE_columns generation.ipynb' and harmonize the column naming as in the data description section of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ftf_2=pd.read_csv(\"../input/FaceTheFuture/face_the_future.csv\",encoding='latin-1')\n",
    "df_ftf_2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verra_Aggregated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extracted  the data from  https://registry.verra.org/app/search/CCB and upload the shape file of the resulting data to the asset section of google earth enginee and then added some metadata to the files as more closely described in 'GEE_columns generation.ipynb' and harmonize the column naming as in the data description section of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verra=pd.read_csv(\"../input/Verra/verra_aggregaated.csv\")\n",
    "df_verra['host_name'] = 'Verra'\n",
    "df_verra.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verra[\"url\"] = 'https://registry.verra.org/app/search/VCS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_verra['site_sqkm'] = pd.to_numeric(df_verra['site_sqkm'], errors='coerce')\n",
    "\n",
    "\n",
    "df_verra['site_sqkm'] = df_verra['site_sqkm'].fillna(0)\n",
    "\n",
    "\n",
    "total = df_verra['site_sqkm'].sum()\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verra = gpd.read_file('/Users/tillkoebe/Downloads/verra_sites.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_verra['project_id_reported'].unique().tolist()).issubset(verra['project_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "960 in verra['project_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verra['description'].str.contains(\"komaza\").any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verra.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_latin_2.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df_plant_2,df_nation_2,df_tist_2,df_tist_w_2,df_asia_2,df_other_2,df_atla_new,df_eco_2,df_ftf_2,df_verra,df_ex,df_latin_2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reference_order = dfs[0].columns.tolist()\n",
    "reordered_dfs = [df[reference_order] for df in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reforestation= pd.concat(reordered_dfs, ignore_index=True)\n",
    "df_reforestation.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering only polygon/Multipolygon rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def is_polygon_or_multipolygon(geometry):\n",
    "    if not isinstance(geometry, str):\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        geometry_dict = json.loads(geometry)\n",
    "        if isinstance(geometry_dict, dict) and 'type' in geometry_dict:\n",
    "            return geometry_dict['type'] in ['Polygon', 'MultiPolygon']\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "    \n",
    "   \n",
    "    try:\n",
    "        geom = wkt.loads(geometry)\n",
    "        return geom.geom_type in ['Polygon', 'MultiPolygon']\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "df_reforestation = df_reforestation[df_reforestation['geometry_reported'].apply(is_polygon_or_multipolygon)]\n",
    "\n",
    "df_reforestation.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering only polygons less than 10000kmsq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def parse_geometry(geometry):\n",
    "    if pd.isnull(geometry):\n",
    "        return None\n",
    "    try:\n",
    "        # Try to parse as JSON\n",
    "        return shape(json.loads(geometry))\n",
    "    except json.JSONDecodeError:\n",
    "        # If JSON parsing fails, try to parse as WKT\n",
    "        try:\n",
    "            return wkt.loads(geometry)\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "df_reforestation['geometry'] = df_reforestation['geometry_reported'].apply(parse_geometry)\n",
    "\n",
    "gdf = gpd.GeoDataFrame(df_reforestation, geometry='geometry')\n",
    "\n",
    "gdf.crs = \"EPSG:4326\"\n",
    "\n",
    "gdf = gdf.to_crs(epsg=3395)\n",
    "\n",
    "gdf.loc[gdf['site_sqkm'].isnull(), 'site_sqkm'] = gdf['geometry'].area / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "gdf['site_sqkm'] = pd.to_numeric(gdf['site_sqkm'], errors='coerce')\n",
    "\n",
    "\n",
    "gdf_filtered = gdf[gdf['site_sqkm'] < 10000]\n",
    "gdf_filtered.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_filtered.drop_duplicates('geometry_reported', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_filtered.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating unique site and projects Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gdf_filtered['created_site_ids'] = ['reforest_site_{}'.format(i) for i in range(1, len(gdf_filtered) + 1)]\n",
    "\n",
    "\n",
    "unique_project_ids = gdf_filtered['project_id_reported'].unique()\n",
    "project_id_mapping = {id: 'reforest_proj_{}'.format(i) for i, id in enumerate(unique_project_ids, 1)}\n",
    "\n",
    "\n",
    "gdf_filtered['created_project_ids'] = gdf_filtered['project_id_reported'].map(project_id_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_filtered.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving The  data to csv\n",
    "#gdf_filtered.to_csv('\"../input/consolidated_reforestation_projects.csv\"', index=False)\n",
    "# Saving the data to GeoJSON\n",
    "gdf_filtered.to_file(\"../input/consolidated_reforestation_projects.geojson\", driver=\"GeoJSON\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
