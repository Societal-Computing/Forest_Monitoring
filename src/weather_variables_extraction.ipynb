{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Climate data Extraction\n",
    "1.Download raster  data for precipitation to Pc from https://www.worldclim.org/\n",
    "\n",
    "2.Overlay polygons and extract rainfall from the centoid pixel of each polygon(Site)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precipitation extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "import pandas as pd\n",
    "import gc\n",
    "from shapely.geometry import Point\n",
    "from helper_functions import extract_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geojson_path = \"../input/Updated_Reforestation_Data.geojson\"\n",
    "output_folder = \"../input/precipitation_output\"\n",
    "tif_folder = \"../climate_precipitation/\"\n",
    "combined_output_path = \"../input/Updated_Reforestation_Data.geojson\"\n",
    "\n",
    "gdf = gpd.read_file(geojson_path)\n",
    "\n",
    "# Checking for the available .tif files\n",
    "tif_files = [f for f in os.listdir(tif_folder) if f.endswith(\".tif\")]\n",
    "if len(tif_files) == 0:\n",
    "    raise FileNotFoundError(\"No .tif files found in the directory.\")\n",
    "\n",
    "\n",
    "tif_path = os.path.join(tif_folder, tif_files[0])\n",
    "with rasterio.open(tif_path) as src:\n",
    "    tif_crs = src.crs\n",
    "\n",
    "# Reprojecting GeoDataFrame if CRS doesn't match\n",
    "if gdf.crs != tif_crs:\n",
    "    gdf = gdf.to_crs(tif_crs)\n",
    "\n",
    "gdf['planting_year'] = gdf['planting_date_reported'].apply(extract_year).astype('Int64')\n",
    "\n",
    "# Organizing the .tif files by year and month\n",
    "tif_files_by_year = {}\n",
    "for tif_file in tif_files:\n",
    "    year_month = tif_file.split(\"_\")[-1].split(\".\")[0]\n",
    "    year, month = int(year_month.split(\"-\")[0]), int(year_month.split(\"-\")[1])\n",
    "    if year not in tif_files_by_year:\n",
    "        tif_files_by_year[year] = {}\n",
    "    tif_files_by_year[year][month] = tif_file\n",
    "\n",
    "# Setting chunk size for processing\n",
    "chunk_size = 200\n",
    "\n",
    "for i in range(0, len(gdf), chunk_size):\n",
    "    gdf_chunk = gdf.iloc[i:i + chunk_size].copy()\n",
    "    precipitation_by_years_after_planting = {}\n",
    "\n",
    "    for idx, polygon in gdf_chunk.iterrows():\n",
    "        planting_year = polygon['planting_year']\n",
    "        if pd.isna(planting_year):\n",
    "            continue\n",
    "\n",
    "        precipitation_by_years_after_planting[idx] = {\n",
    "            'planting_year': 0, 'year_1': 0, 'year_2': 0, 'year_5': 0,\n",
    "            'has_data_planting': False, 'has_data_1': False, 'has_data_2': False, 'has_data_5': False\n",
    "        }\n",
    "\n",
    "        centroid = polygon['geometry'].centroid\n",
    "        centroid_point = [(centroid.x, centroid.y)]\n",
    "\n",
    "        for year_offset in [0, 1, 2, 5]:\n",
    "            current_year = planting_year + year_offset\n",
    "            if current_year in tif_files_by_year:\n",
    "                total_precipitation_for_year = 0\n",
    "                has_valid_data = False\n",
    "\n",
    "                for month in range(1, 13):\n",
    "                    if month in tif_files_by_year[current_year]:\n",
    "                        tif_file = tif_files_by_year[current_year][month]\n",
    "                        tif_path = os.path.join(tif_folder, tif_file)\n",
    "\n",
    "                        try:\n",
    "                            with rasterio.open(tif_path) as src:\n",
    "                                for val in src.sample(centroid_point):\n",
    "                                    valid_data = val[0]\n",
    "                                    if not np.isnan(valid_data):\n",
    "                                        total_precipitation_for_year += valid_data\n",
    "                                        has_valid_data = True\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error processing {tif_file}: {e}\")\n",
    "\n",
    "                # Updating precipitation data\n",
    "                if year_offset == 0:\n",
    "                    precipitation_by_years_after_planting[idx]['planting_year'] = total_precipitation_for_year\n",
    "                    precipitation_by_years_after_planting[idx]['has_data_planting'] = has_valid_data\n",
    "                elif year_offset == 1:\n",
    "                    precipitation_by_years_after_planting[idx]['year_1'] = total_precipitation_for_year\n",
    "                    precipitation_by_years_after_planting[idx]['has_data_1'] = has_valid_data\n",
    "                elif year_offset == 2:\n",
    "                    precipitation_by_years_after_planting[idx]['year_2'] = total_precipitation_for_year\n",
    "                    precipitation_by_years_after_planting[idx]['has_data_2'] = has_valid_data\n",
    "                elif year_offset == 5:\n",
    "                    precipitation_by_years_after_planting[idx]['year_5'] = total_precipitation_for_year\n",
    "                    precipitation_by_years_after_planting[idx]['has_data_5'] = has_valid_data\n",
    "\n",
    "  \n",
    "    for idx, precipitation_data in precipitation_by_years_after_planting.items():\n",
    "        gdf_chunk.at[idx, \"avg_precipitation_planting_year\"] = precipitation_data['planting_year'] / 12 if precipitation_data['has_data_planting'] else np.nan\n",
    "        gdf_chunk.at[idx, \"avg_precipitation_1_year_after\"] = precipitation_data['year_1'] / 12 if precipitation_data['has_data_1'] else np.nan\n",
    "        gdf_chunk.at[idx, \"avg_precipitation_2_years_after\"] = precipitation_data['year_2'] / 12 if precipitation_data['has_data_2'] else np.nan\n",
    "        gdf_chunk.at[idx, \"avg_precipitation_5_years_after\"] = precipitation_data['year_5'] / 12 if precipitation_data['has_data_5'] else np.nan\n",
    "\n",
    "    output_geojson_path = os.path.join(output_folder, f\"df_reforestation_chunk_{i}.geojson\")\n",
    "    gdf_chunk.to_file(output_geojson_path, driver=\"GeoJSON\")\n",
    "\n",
    "    del gdf_chunk, precipitation_by_years_after_planting\n",
    "    gc.collect()\n",
    "\n",
    "    print(f\"Processed and saved chunk {i} to {output_geojson_path}\")\n",
    "\n",
    "# Combining all chunks into a single GeoDataFrame\n",
    "combined_gdf = gpd.GeoDataFrame()\n",
    "\n",
    "for i in range(0, len(gdf), chunk_size):\n",
    "    chunk_path = os.path.join(output_folder, f\"df_reforestation_chunk_{i}.geojson\")\n",
    "    chunk_gdf = gpd.read_file(chunk_path)\n",
    "    combined_gdf = pd.concat([combined_gdf, chunk_gdf], ignore_index=True)\n",
    "\n",
    "# Saving the combined GeoDataFrame to a single file\n",
    "combined_gdf.to_file(combined_output_path, driver=\"GeoJSON\")\n",
    "print(f\"Combined all chunks into {combined_output_path}\")\n",
    "\n",
    "# Deleting individual chunk files to free up space\n",
    "for i in range(0, len(gdf), chunk_size):\n",
    "    chunk_path = os.path.join(output_folder, f\"df_reforestation_chunk_{i}.geojson\")\n",
    "    os.remove(chunk_path)\n",
    "    print(f\"Deleted chunk file: {chunk_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum and Minimum Temperatuture \n",
    "1.Download raster  data for tmax(Maximum Temperature) and tmin (Minimum Temperature) 2.5  to Pc from https://www.worldclim.org/\n",
    "2.Overlay polygons and extract rainfall from the centoid pixel of each polygon(Site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "geojson_path = \"../input/Updated_Reforestation_Data.geojson\"\n",
    "output_folder = \"../input/tmax_output\"\n",
    "tif_folder = \"../climate_tmax/\"\n",
    "combined_output_path = \"../input/Updated_Reforestation_Data.geojson\"\n",
    "\n",
    "\n",
    "gdf = gpd.read_file(geojson_path)\n",
    "\n",
    "# Checking for the available .tif files\n",
    "tif_files = [f for f in os.listdir(tif_folder) if f.endswith(\".tif\")]\n",
    "if len(tif_files) == 0:\n",
    "    raise FileNotFoundError(\"No .tif files found in the directory.\")\n",
    "\n",
    "\n",
    "tif_path = os.path.join(tif_folder, tif_files[0])\n",
    "with rasterio.open(tif_path) as src:\n",
    "    tif_crs = src.crs\n",
    "\n",
    "# Reprojecting GeoDataFrame if CRS doesn't match\n",
    "if gdf.crs != tif_crs:\n",
    "    gdf = gdf.to_crs(tif_crs)\n",
    "\n",
    "\n",
    "gdf['planting_year'] = gdf['planting_date_reported'].apply(extract_year).astype('Int64')\n",
    "\n",
    "\n",
    "tif_files_by_year = {}\n",
    "for tif_file in tif_files:\n",
    "    year_month = tif_file.split(\"_\")[-1].split(\".\")[0]  \n",
    "    year, month = int(year_month.split(\"-\")[0]), int(year_month.split(\"-\")[1])\n",
    "    if year not in tif_files_by_year:\n",
    "        tif_files_by_year[year] = {}\n",
    "    tif_files_by_year[year][month] = tif_file\n",
    "\n",
    "\n",
    "chunk_size = 200  \n",
    "\n",
    "\n",
    "for i in range(0, len(gdf), chunk_size):\n",
    "    gdf_chunk = gdf.iloc[i:i + chunk_size].copy()\n",
    "    tmax_by_years_after_planting = {}\n",
    "\n",
    "    for idx, polygon in gdf_chunk.iterrows():\n",
    "        planting_year = polygon['planting_year']\n",
    "        if pd.isna(planting_year):\n",
    "            continue\n",
    "\n",
    "        tmax_by_years_after_planting[idx] = {\n",
    "            'planting_year': 0, 'year_1': 0, 'year_2': 0, 'year_5': 0,\n",
    "            'has_data_planting': False, 'has_data_1': False, 'has_data_2': False, 'has_data_5': False\n",
    "        }\n",
    "\n",
    "        centroid = polygon['geometry'].centroid\n",
    "        centroid_point = [(centroid.x, centroid.y)]\n",
    "\n",
    "        for year_offset in [0, 1, 2, 5]:\n",
    "            current_year = planting_year + year_offset\n",
    "            if current_year in tif_files_by_year:\n",
    "                total_tmax_for_year = 0\n",
    "                has_valid_data = False\n",
    "\n",
    "                for month in range(1, 13):\n",
    "                    if month in tif_files_by_year[current_year]:\n",
    "                        tif_file = tif_files_by_year[current_year][month]\n",
    "                        tif_path = os.path.join(tif_folder, tif_file)\n",
    "\n",
    "                        try:\n",
    "                            with rasterio.open(tif_path) as src:\n",
    "                                for val in src.sample(centroid_point):\n",
    "                                    valid_data = val[0]\n",
    "                                    if not np.isnan(valid_data):\n",
    "                                        total_tmax_for_year += valid_data\n",
    "                                        has_valid_data = True\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error processing {tif_file}: {e}\")\n",
    "\n",
    "                # Updating Tmax data\n",
    "                if year_offset == 0:\n",
    "                    tmax_by_years_after_planting[idx]['planting_year'] = total_tmax_for_year\n",
    "                    tmax_by_years_after_planting[idx]['has_data_planting'] = has_valid_data\n",
    "                elif year_offset == 1:\n",
    "                    tmax_by_years_after_planting[idx]['year_1'] = total_tmax_for_year\n",
    "                    tmax_by_years_after_planting[idx]['has_data_1'] = has_valid_data\n",
    "                elif year_offset == 2:\n",
    "                    tmax_by_years_after_planting[idx]['year_2'] = total_tmax_for_year\n",
    "                    tmax_by_years_after_planting[idx]['has_data_2'] = has_valid_data\n",
    "                elif year_offset == 5:\n",
    "                    tmax_by_years_after_planting[idx]['year_5'] = total_tmax_for_year\n",
    "                    tmax_by_years_after_planting[idx]['has_data_5'] = has_valid_data\n",
    "\n",
    "  \n",
    "    for idx, tmax_data in tmax_by_years_after_planting.items():\n",
    "        gdf_chunk.at[idx, \"avg_tmax_planting_year\"] = tmax_data['planting_year'] / 12 if tmax_data['has_data_planting'] else np.nan\n",
    "        gdf_chunk.at[idx, \"avg_tmax_1_year_after\"] = tmax_data['year_1'] / 12 if tmax_data['has_data_1'] else np.nan\n",
    "        gdf_chunk.at[idx, \"avg_tmax_2_years_after\"] = tmax_data['year_2'] / 12 if tmax_data['has_data_2'] else np.nan\n",
    "        gdf_chunk.at[idx, \"avg_tmax_5_years_after\"] = tmax_data['year_5'] / 12 if tmax_data['has_data_5'] else np.nan\n",
    "\n",
    "    output_geojson_path = os.path.join(output_folder, f\"df_reforestation_chunk_{i}.geojson\")\n",
    "    gdf_chunk.to_file(output_geojson_path, driver=\"GeoJSON\")\n",
    "\n",
    "    del gdf_chunk, tmax_by_years_after_planting\n",
    "    gc.collect()\n",
    "\n",
    "    print(f\"Processed and saved chunk {i} to {output_geojson_path}\")\n",
    "\n",
    "combined_gdf = gpd.GeoDataFrame()\n",
    "\n",
    "for i in range(0, len(gdf), chunk_size):\n",
    "    chunk_path = os.path.join(output_folder, f\"df_reforestation_chunk_{i}.geojson\")\n",
    "    chunk_gdf = gpd.read_file(chunk_path)\n",
    "    combined_gdf = pd.concat([combined_gdf, chunk_gdf], ignore_index=True)\n",
    "\n",
    "\n",
    "combined_gdf.to_file(combined_output_path, driver=\"GeoJSON\")\n",
    "print(f\"Combined all chunks into {combined_output_path}\")\n",
    "\n",
    "\n",
    "for i in range(0, len(gdf), chunk_size):\n",
    "    chunk_path = os.path.join(output_folder, f\"df_reforestation_chunk_{i}.geojson\")\n",
    "    os.remove(chunk_path)\n",
    "    print(f\"Deleted chunk file: {chunk_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "geojson_path = \"../input/Updated_Reforestation_Data.geojson\"\n",
    "output_folder = \"../input/tmin_output\"\n",
    "tif_folder = \"../climate_tmin/\"\n",
    "combined_output_path = \"../input/Updated_Reforestation_Data.geojson\" \n",
    "\n",
    "\n",
    "gdf = gpd.read_file(geojson_path)\n",
    "\n",
    "\n",
    "tif_files = [f for f in os.listdir(tif_folder) if f.endswith(\".tif\")]\n",
    "if len(tif_files) == 0:\n",
    "    raise FileNotFoundError(\"No .tif files found in the directory.\")\n",
    "\n",
    "tif_path = os.path.join(tif_folder, tif_files[0])\n",
    "with rasterio.open(tif_path) as src:\n",
    "    tif_crs = src.crs\n",
    "\n",
    "if gdf.crs != tif_crs:\n",
    "    gdf = gdf.to_crs(tif_crs)\n",
    "\n",
    "tif_files_by_year = {}\n",
    "for tif_file in tif_files:\n",
    "    year_month = tif_file.split(\"_\")[-1].split(\".\")[0]  \n",
    "    year, month = int(year_month.split(\"-\")[0]), int(year_month.split(\"-\")[1])\n",
    "    if year not in tif_files_by_year:\n",
    "        tif_files_by_year[year] = {}\n",
    "    tif_files_by_year[year][month] = tif_file\n",
    "\n",
    "\n",
    "chunk_size = 200  \n",
    "\n",
    "\n",
    "for i in range(0, len(gdf), chunk_size):\n",
    "    gdf_chunk = gdf.iloc[i:i + chunk_size].copy()\n",
    "    tmin_by_years_after_planting = {}\n",
    "\n",
    "    for idx, polygon in gdf_chunk.iterrows():\n",
    "        planting_year = polygon['planting_year']\n",
    "        if pd.isna(planting_year):\n",
    "            continue\n",
    "\n",
    "        tmin_by_years_after_planting[idx] = {\n",
    "            'planting_year': 0, 'year_1': 0, 'year_2': 0, 'year_5': 0,\n",
    "            'has_data_planting': False, 'has_data_1': False, 'has_data_2': False, 'has_data_5': False\n",
    "        }\n",
    "\n",
    "        centroid = polygon['geometry'].centroid\n",
    "        centroid_point = [(centroid.x, centroid.y)]\n",
    "\n",
    "        for year_offset in [0, 1, 2, 5]:\n",
    "            current_year = planting_year + year_offset\n",
    "            if current_year in tif_files_by_year:\n",
    "                total_tmin_for_year = 0\n",
    "                has_valid_data = False\n",
    "\n",
    "                for month in range(1, 13):\n",
    "                    if month in tif_files_by_year[current_year]:\n",
    "                        tif_file = tif_files_by_year[current_year][month]\n",
    "                        tif_path = os.path.join(tif_folder, tif_file)\n",
    "\n",
    "                        try:\n",
    "                            with rasterio.open(tif_path) as src:\n",
    "                                for val in src.sample(centroid_point):\n",
    "                                    valid_data = val[0]\n",
    "                                    if not np.isnan(valid_data):\n",
    "                                        total_tmin_for_year += valid_data\n",
    "                                        has_valid_data = True\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error processing {tif_file}: {e}\")\n",
    "\n",
    "                # Updating Tmin data\n",
    "                if year_offset == 0:\n",
    "                    tmin_by_years_after_planting[idx]['planting_year'] = total_tmin_for_year\n",
    "                    tmin_by_years_after_planting[idx]['has_data_planting'] = has_valid_data\n",
    "                elif year_offset == 1:\n",
    "                    tmin_by_years_after_planting[idx]['year_1'] = total_tmin_for_year\n",
    "                    tmin_by_years_after_planting[idx]['has_data_1'] = has_valid_data\n",
    "                elif year_offset == 2:\n",
    "                    tmin_by_years_after_planting[idx]['year_2'] = total_tmin_for_year\n",
    "                    tmin_by_years_after_planting[idx]['has_data_2'] = has_valid_data\n",
    "                elif year_offset == 5:\n",
    "                    tmin_by_years_after_planting[idx]['year_5'] = total_tmin_for_year\n",
    "                    tmin_by_years_after_planting[idx]['has_data_5'] = has_valid_data\n",
    "\n",
    " \n",
    "    for idx, tmin_data in tmin_by_years_after_planting.items():\n",
    "        gdf_chunk.at[idx, \"avg_tmin_planting_year\"] = tmin_data['planting_year'] / 12 if tmin_data['has_data_planting'] else np.nan\n",
    "        gdf_chunk.at[idx, \"avg_tmin_1_year_after\"] = tmin_data['year_1'] / 12 if tmin_data['has_data_1'] else np.nan\n",
    "        gdf_chunk.at[idx, \"avg_tmin_2_years_after\"] = tmin_data['year_2'] / 12 if tmin_data['has_data_2'] else np.nan\n",
    "        gdf_chunk.at[idx, \"avg_tmin_5_years_after\"] = tmin_data['year_5'] / 12 if tmin_data['has_data_5'] else np.nan\n",
    "\n",
    "    output_geojson_path = os.path.join(output_folder, f\"df_reforestation_chunk_{i}.geojson\")\n",
    "    gdf_chunk.to_file(output_geojson_path, driver=\"GeoJSON\")\n",
    "\n",
    "    del gdf_chunk, tmin_by_years_after_planting\n",
    "    gc.collect()\n",
    "\n",
    "    print(f\"Processed and saved chunk {i} to {output_geojson_path}\")\n",
    "\n",
    "combined_gdf = gpd.GeoDataFrame()\n",
    "\n",
    "for i in range(0, len(gdf), chunk_size):\n",
    "    chunk_path = os.path.join(output_folder, f\"df_reforestation_chunk_{i}.geojson\")\n",
    "    chunk_gdf = gpd.read_file(chunk_path)\n",
    "    combined_gdf = pd.concat([combined_gdf, chunk_gdf], ignore_index=True)\n",
    "\n",
    "\n",
    "combined_gdf.to_file(combined_output_path, driver=\"GeoJSON\")\n",
    "print(f\"Combined all chunks into {combined_output_path}\")\n",
    "\n",
    "for i in range(0, len(gdf), chunk_size):\n",
    "    chunk_path = os.path.join(output_folder, f\"df_reforestation_chunk_{i}.geojson\")\n",
    "    os.remove(chunk_path)\n",
    "    print(f\"Deleted chunk file: {chunk_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
