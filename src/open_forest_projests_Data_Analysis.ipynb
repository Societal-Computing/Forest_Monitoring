{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112 entries, 0 to 111\n",
      "Data columns (total 24 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   index                              112 non-null    object \n",
      " 1   id                                 112 non-null    int64  \n",
      " 2   pageProps.projects.hits.hits.sort  112 non-null    int64  \n",
      " 3   project_id                         112 non-null    int64  \n",
      " 4   type                               112 non-null    object \n",
      " 5   regionShortCode                    111 non-null    object \n",
      " 6   developer                          112 non-null    object \n",
      " 7   name                               112 non-null    object \n",
      " 8   region                             112 non-null    object \n",
      " 9   polygonCoordinate                  112 non-null    object \n",
      " 10  square                             112 non-null    float64\n",
      " 11  cidScreenShot                      112 non-null    object \n",
      " 12  iconCidDir                         112 non-null    object \n",
      " 13  aboutProject                       112 non-null    object \n",
      " 14  goals                              112 non-null    object \n",
      " 15  leakage.zones                      112 non-null    object \n",
      " 16  X__N_SSG                           112 non-null    bool   \n",
      " 17  attribute_carbon                   7 non-null      object \n",
      " 18  leakage.leakage                    7 non-null      float64\n",
      " 19  leakage.rainfall                   7 non-null      float64\n",
      " 20  leakage.baselineDefaultValue       7 non-null      float64\n",
      " 21  leakage.carbonApprove              7 non-null      float64\n",
      " 22  leakage.forestType.type            7 non-null      float64\n",
      " 23  leakage.forestType.tree            7 non-null      float64\n",
      "dtypes: bool(1), float64(7), int64(3), object(13)\n",
      "memory usage: 20.4+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('Atlas_data_frame.json')\n",
    "\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_trailing_zeros(s):\n",
    "  \n",
    "    if s.startswith('list(c(') and s.endswith(')'):\n",
    "       \n",
    "        s = s[7:-1]\n",
    "  \n",
    "    list_of_strings = s.split(',')\n",
    "   \n",
    "    list_of_strings = [s.strip().lstrip('c(').rstrip(')') for s in list_of_strings]\n",
    "    \n",
    "    list_of_floats = list(map(float, list_of_strings))\n",
    "   \n",
    "    while list_of_floats and list_of_floats[-1] == 0.0:\n",
    "        list_of_floats.pop()\n",
    "   \n",
    "    return ', '.join(map(str, list_of_floats))\n",
    "\n",
    "\n",
    "df['polygonCoordinate'] = df['polygonCoordinate'].apply(remove_trailing_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import simplekml\n",
    "import os\n",
    "\n",
    "if not os.path.exists('kml'):\n",
    "    os.makedirs('kml')\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    coords = list(map(float, row['polygonCoordinate'].split(',')))\n",
    "\n",
    "   \n",
    "    half = len(coords) // 2\n",
    "    lats = coords[:half]\n",
    "    longs = coords[half:]\n",
    "\n",
    "   \n",
    "    polygon_coords = list(zip(lats, longs))\n",
    "\n",
    "\n",
    "    kml = simplekml.Kml()\n",
    "\n",
    "    pol = kml.newpolygon(name=\"Polygon{}\".format(index), outerboundaryis=polygon_coords)\n",
    "\n",
    "    pol.style.polystyle.color = simplekml.Color.changealphaint(0, simplekml.Color.white)\n",
    "\n",
    "    \n",
    "    pol.style.linestyle.color = simplekml.Color.red\n",
    "\n",
    "    kml.save(os.path.join(\"kml\", \"Polygon{}.kml\".format(index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('OPF.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -97.9555704, -97.9555678, -97.9558387, -97.955...\n",
       "1      79.4147657, 79.4147415, 79.4150232, 79.4151144...\n",
       "2      34.5074755574286, 34.50678510184, 34.506173427...\n",
       "3      -89.5362508149241, -89.5350081672492, -89.5349...\n",
       "4      -89.528162, -89.5273918, -89.531951, -89.53207...\n",
       "                             ...                        \n",
       "107    -76.4360839189999, -76.435808104, -76.43591829...\n",
       "108    -76.443557912, -76.4437644598984, -76.44401264...\n",
       "109    -76.43563696, -76.4351364539999, -76.435444542...\n",
       "110    -76.444705495, -76.445244465, -76.445595946999...\n",
       "111    -76.439519735, -76.4398112629999, -76.4399827,...\n",
       "Name: polygonCoordinate, Length: 112, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"polygonCoordinate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of KML files:  112\n"
     ]
    }
   ],
   "source": [
    "import simplekml\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "output_dir = \"Kml_files\"\n",
    "\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    kml = simplekml.Kml()\n",
    "  \n",
    "    coordinates_list = row['polygonCoordinate'][7:-1].split(', ')\n",
    " \n",
    "    coordinates_list = [coord.replace('c(', '').replace(')', '') for coord in coordinates_list]\n",
    "  \n",
    "    coordinates_list = [coord for coord in coordinates_list if coord]\n",
    "  \n",
    "    coord_length = len(coordinates_list) // 3\n",
    "    \n",
    "    longitudes = coordinates_list[:coord_length]\n",
    "    latitudes = coordinates_list[coord_length:2*coord_length]\n",
    "    altitudes = coordinates_list[2*coord_length:]\n",
    "\n",
    "    coordinates = list(zip(map(float, longitudes), map(float, latitudes), map(float, altitudes)))\n",
    "    if coordinates:  \n",
    "        pol = kml.newpolygon(name=\"Polygon {}\".format(index), outerboundaryis=coordinates)\n",
    "        pol.style.polystyle.color = simplekml.Color.changealphaint(0, simplekml.Color.red)  \n",
    "        pol.style.linestyle.color = simplekml.Color.red \n",
    "        kml.save(os.path.join(output_dir, \"Polygon_{}.kml\".format(index)))\n",
    "\n",
    "kml_files = glob.glob(os.path.join(output_dir, '*.kml'))\n",
    "print(\"Number of KML files: \", len(kml_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of KML files:  112\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "output_dir = \"Kml_files\"\n",
    "\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    kml = simplekml.Kml()\n",
    " \n",
    "    coordinates_list = row['polygonCoordinate'][7:-1].split(', ')\n",
    " \n",
    "    coordinates_list = [coord.replace('c(', '').replace(')', '') for coord in coordinates_list]\n",
    "    mid_index = len(coordinates_list) // 2\n",
    "    longitudes = coordinates_list[:mid_index]\n",
    "    latitudes = coordinates_list[mid_index:-1]  \n",
    "    coordinates = list(zip(map(float, latitudes), map(float, longitudes))) \n",
    "    if coordinates: \n",
    "        pol = kml.newpolygon(name=\"Polygon {}\".format(index), outerboundaryis=coordinates)\n",
    "        pol.style.polystyle.color = simplekml.Color.changealphaint(0, simplekml.Color.red)  \n",
    "        pol.style.linestyle.color = simplekml.Color.red  \n",
    "        kml.save(os.path.join(output_dir, \"Polygon_{}.kml\".format(index)))\n",
    "\n",
    "\n",
    "kml_files = glob.glob(os.path.join(output_dir, '*.kml'))\n",
    "print(\"Number of KML files: \", len(kml_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VERRA DATA EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/idisc02/Forest_Project_New/Forest_Monitoring/input/Verra_Projects/TIST KE PD-VCS-011d App03a PA Plots 230701.kml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m  \u001b[38;5;66;03m# Add this import\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Parse the KML file\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/idisc02/Forest_Project_New/Forest_Monitoring/input/Verra_Projects/TIST KE PD-VCS-011d App03a PA Plots 230701.kml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m kml_file:\n\u001b[1;32m      8\u001b[0m     kml_content \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mparse(kml_file)\u001b[38;5;241m.\u001b[39mgetroot()\u001b[38;5;241m.\u001b[39mDocument\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Initialize lists to hold the data\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/downgrade/lib/python3.8/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/idisc02/Forest_Project_New/Forest_Monitoring/input/Verra_Projects/TIST KE PD-VCS-011d App03a PA Plots 230701.kml'"
     ]
    }
   ],
   "source": [
    "from pykml import parser\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import re \n",
    "\n",
    "\n",
    "with open('/home/idisc02/Forest_Project_New/Forest_Monitoring/input/Verra_Projects/TIST KE PD-VCS-011d App03a PA Plots 230701.kml', 'r') as kml_file:\n",
    "    kml_content = parser.parse(kml_file).getroot().Document\n",
    "\n",
    "\n",
    "ids = []\n",
    "coordinates = []\n",
    "extended_data_list = [] \n",
    "\n",
    "\n",
    "def parse_coordinates(coordinate_string):\n",
    "    coordinate_list = re.split(r'\\s+', coordinate_string.strip())\n",
    "    return [(float(coordinate.split(',')[1]), float(coordinate.split(',')[0])) for coordinate in coordinate_list]\n",
    "\n",
    "\n",
    "for folder in kml_content.Folder:\n",
    "  \n",
    "    for placemark in folder.Placemark:\n",
    "        if hasattr(placemark, 'name'):\n",
    "            id = placemark.name.text\n",
    "        else:\n",
    "            id = None\n",
    "        if hasattr(placemark, 'ExtendedData'):\n",
    "            extended_data = {}\n",
    "            for data in placemark.ExtendedData.SchemaData.SimpleData:\n",
    "                extended_data[data.attrib['name']] = data.text\n",
    "            extended_data_list.append(extended_data)\n",
    "        else:\n",
    "            extended_data_list.append(None)\n",
    "        if hasattr(placemark, 'Point'):\n",
    "            coordinate = placemark.Point.coordinates.text.strip().split(',')\n",
    "            longitude, latitude = list(map(float, coordinate))\n",
    "            ids.append(id)\n",
    "            coordinates.append([(latitude, longitude)])\n",
    "        elif hasattr(placemark, 'LineString'):\n",
    "            coordinate_string = placemark.LineString.coordinates.text\n",
    "            ids.append(id)\n",
    "            coordinates.append(parse_coordinates(coordinate_string))\n",
    "        elif hasattr(placemark, 'MultiGeometry'):\n",
    "            for polygon in placemark.MultiGeometry.Polygon:\n",
    "                coordinate_string = polygon.outerBoundaryIs.LinearRing.coordinates.text\n",
    "                ids.append(id)\n",
    "                coordinates.append(parse_coordinates(coordinate_string))\n",
    "        elif hasattr(placemark, 'Polygon'):\n",
    "            coordinate_string = placemark.Polygon.outerBoundaryIs.LinearRing.coordinates.text\n",
    "            ids.append(id)\n",
    "            coordinates.append(parse_coordinates(coordinate_string))\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'ID': ids,\n",
    "    'Coordinates': coordinates,\n",
    "    'ExtendedData': extended_data_list \n",
    "})\n",
    "\n",
    "\n",
    "df.to_csv('kenya_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "no such child: {http://www.opengis.net/kml/2.2}name",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Iterate over the Placemarks in the KML file\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m placemark \u001b[38;5;129;01min\u001b[39;00m kml_content\u001b[38;5;241m.\u001b[39mFolder\u001b[38;5;241m.\u001b[39mPlacemark:\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mplacemark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m     16\u001b[0m     geometry \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(placemark, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPoint\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32msrc/lxml/objectify.pyx:234\u001b[0m, in \u001b[0;36mlxml.objectify.ObjectifiedElement.__getattr__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/lxml/objectify.pyx:453\u001b[0m, in \u001b[0;36mlxml.objectify._lookupChildOrRaise\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: no such child: {http://www.opengis.net/kml/2.2}name"
     ]
    }
   ],
   "source": [
    "from pykml import parser\n",
    "from os import path\n",
    "import pandas as pd\n",
    "\n",
    "# Parse the KML file\n",
    "with open('/home/idisc02/Forest_Project_New/Forest_Monitoring/input/Verra_Projects/kml_files/03-Dingxi_Project boundary.kml', 'r') as kml_file:\n",
    "    kml_content = parser.parse(kml_file).getroot().Document\n",
    "\n",
    "# Initialize lists to hold the data\n",
    "ids = []\n",
    "geometries = []\n",
    "\n",
    "# Iterate over the Placemarks in the KML file\n",
    "for placemark in kml_content.Folder.Placemark:\n",
    "    id = placemark.name.text\n",
    "    geometry = []\n",
    "    if hasattr(placemark, 'Point'):\n",
    "        coordinates = placemark.Point.coordinates.text.strip().split(',')\n",
    "        longitude, latitude = map(float, coordinates)\n",
    "        geometry.append((latitude, longitude))\n",
    "    elif hasattr(placemark, 'LineString'):\n",
    "        coordinates = placemark.LineString.coordinates.text.strip().split(' ')\n",
    "        for coordinate in coordinates:\n",
    "            longitude, latitude = map(float, coordinate.split(','))\n",
    "            geometry.append((latitude, longitude))\n",
    "    ids.append(id)\n",
    "    geometries.append(geometry)\n",
    "\n",
    "# Save the data to a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'ID': ids,\n",
    "    'Polygon_Geometry': geometries\n",
    "})\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv('/home/idisc02/Forest_Project_New/Forest_Monitoring/input/Verra_Projects/kml_files/03-Dingxi_Project boundary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "no such child: {http://www.opengis.net/kml/2.2}LineString",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m placemark \u001b[38;5;129;01min\u001b[39;00m kml_content\u001b[38;5;241m.\u001b[39mFolder\u001b[38;5;241m.\u001b[39mPlacemark:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m placemark\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m---> 16\u001b[0m     coordinates \u001b[38;5;241m=\u001b[39m \u001b[43mplacemark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLineString\u001b[49m\u001b[38;5;241m.\u001b[39mcoordinates\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m     geometry \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m coordinate \u001b[38;5;129;01min\u001b[39;00m coordinates:\n",
      "File \u001b[0;32msrc/lxml/objectify.pyx:234\u001b[0m, in \u001b[0;36mlxml.objectify.ObjectifiedElement.__getattr__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/lxml/objectify.pyx:453\u001b[0m, in \u001b[0;36mlxml.objectify._lookupChildOrRaise\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: no such child: {http://www.opengis.net/kml/2.2}LineString"
     ]
    }
   ],
   "source": [
    "from pykml import parser\n",
    "from os import path\n",
    "import pandas as pd\n",
    "\n",
    "# Parse the KML file\n",
    "with open('/home/idisc02/Forest_Project_New/Forest_Monitoring/input/Verra_Projects/TIST KE PD-VCS-001d App03 PA Plots.kml', 'r') as kml_file:\n",
    "    kml_content = parser.parse(kml_file).getroot().Document\n",
    "\n",
    "# Initialize lists to hold the data\n",
    "ids = []\n",
    "geometries = []\n",
    "\n",
    "# Iterate over the Placemarks in the KML file\n",
    "for placemark in kml_content.Folder.Placemark:\n",
    "    id = placemark.name.text\n",
    "    coordinates = placemark.LineString.coordinates.text.strip().split(' ')\n",
    "    geometry = []\n",
    "    for coordinate in coordinates:\n",
    "        longitude, latitude, altitude = map(float, coordinate.split(','))\n",
    "        geometry.append((latitude, longitude))\n",
    "    ids.append(id)\n",
    "    geometries.append(geometry)\n",
    "\n",
    "# Save the data to a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'ID': ids,\n",
    "    'Polygon_Geometry': geometries\n",
    "})\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv('Kenya_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykml import parser\n",
    "from os import path\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "with open('/home/idisc02/Forest_Project_New/Forest_Monitoring/input/Verra_Projects/kml_files/03-Dingxi_Project boundary.kml', 'r') as kml_file:\n",
    "    kml_content = parser.parse(kml_file).getroot().Document\n",
    "\n",
    "\n",
    "names = []\n",
    "descriptions = []\n",
    "coordinates = []\n",
    "\n",
    "\n",
    "def parse_coordinates(coordinate_string):\n",
    "    coordinate_list = coordinate_string.strip().split()\n",
    "    return [(float(coordinate.split(',')[1]), float(coordinate.split(',')[0])) for coordinate in coordinate_list]\n",
    "\n",
    "def parse_description(description):\n",
    "    if description is None:\n",
    "        return None\n",
    "    soup = BeautifulSoup(description, 'html.parser')\n",
    "    table = soup.find('table')\n",
    "    data = {}\n",
    "    for row in table.find_all('tr'):\n",
    "        cells = row.find_all('td')\n",
    "        if len(cells) > 1:\n",
    "            key = cells[0].text.strip().replace(':', '')\n",
    "            value = cells[1].text.strip()\n",
    "            data[key] = value\n",
    "    return data\n",
    "\n",
    "\n",
    "for folder in kml_content.Folder:\n",
    "\n",
    "    for placemark in folder.Placemark:\n",
    "        name = placemark.name.text if hasattr(placemark, 'name') else None\n",
    "        description = parse_description(placemark.description.text) if hasattr(placemark, 'description') and placemark.description.text is not None else None\n",
    "        if hasattr(placemark, 'Point'):\n",
    "            coordinate = parse_coordinates(placemark.Point.coordinates.text)\n",
    "        elif hasattr(placemark, 'LineString'):\n",
    "            coordinate = parse_coordinates(placemark.LineString.coordinates.text)\n",
    "        else:\n",
    "            coordinate = None\n",
    "        names.append(name)\n",
    "        descriptions.append(description)\n",
    "        coordinates.append(coordinate)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Name': names,\n",
    "    'Description': descriptions,\n",
    "    'Coordinates': coordinates\n",
    "})\n",
    "\n",
    "\n",
    "df.to_csv('/home/idisc02/Forest_Project_New/Forest_Monitoring/input/Verra_Projects/kml_files/03-Dingxi_Project boundary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykml import parser\n",
    "from os import path\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Parse the KML file\n",
    "with open('/home/idisc02/Forest_Project_New/Forest_Monitoring/input/Verra_Projects/kml_files/03-Dingxi_Project boundary.kml', 'r') as kml_file:\n",
    "    kml_content = parser.parse(kml_file).getroot().Document\n",
    "\n",
    "\n",
    "kcodes = []\n",
    "plant_years = []\n",
    "layers = []\n",
    "paths = []\n",
    "coordinates = []\n",
    "\n",
    "\n",
    "def parse_coordinates(coordinate_string):\n",
    "    coordinate_list = coordinate_string.strip().split()\n",
    "    return [(float(coordinate.split(',')[0]), float(coordinate.split(',')[1])) for coordinate in coordinate_list]\n",
    "\n",
    "\n",
    "for folder in kml_content.Folder:\n",
    "\n",
    "    for placemark in folder.Placemark:\n",
    "        kcode = placemark.ExtendedData.SchemaData.getchildren()[0].text\n",
    "        plant_year = placemark.ExtendedData.SchemaData.getchildren()[1].text\n",
    "        layer = placemark.ExtendedData.SchemaData.getchildren()[2].text\n",
    "        path = placemark.ExtendedData.SchemaData.getchildren()[3].text\n",
    "        coordinate = parse_coordinates(placemark.MultiGeometry.Polygon.outerBoundaryIs.LinearRing.coordinates.text)\n",
    "        kcodes.append(kcode)\n",
    "        plant_years.append(plant_year)\n",
    "        layers.append(layer)\n",
    "        paths.append(path)\n",
    "        coordinates.append(coordinate)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'kcode': kcodes,\n",
    "    'PlantYear': plant_years,\n",
    "    'layer': layers,\n",
    "    'path': paths,\n",
    "    'Coordinates': coordinates\n",
    "})\n",
    "\n",
    "\n",
    "df.to_csv('/home/idisc02/Forest_Project_New/Forest_Monitoring/input/Verra_Projects/kml_files/03-Dingxi_Project boundary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykml import parser\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "\n",
    "\n",
    "kml_file_path = '/home/idisc02/Forest_Project_New/Forest_Monitoring/input/Verra_Projects/kml_files/05-Zhanjiang AR_Project boundary.kml'\n",
    "\n",
    "\n",
    "def parse_coordinates(coordinate_string):\n",
    "    coordinate_list = coordinate_string.strip().split()\n",
    "    return [(float(coordinate.split(',')[0]), float(coordinate.split(',')[1])) for coordinate in coordinate_list]\n",
    "\n",
    "\n",
    "areas = []\n",
    "coordinates = []\n",
    "\n",
    "\n",
    "with open(kml_file_path, 'r') as kml_file:\n",
    "    kml_content = parser.parse(kml_file).getroot()\n",
    "    namespaces = {'kml': 'http://www.opengis.net/kml/2.2'}\n",
    "\n",
    "    for placemark in kml_content.findall('.//kml:Placemark', namespaces):\n",
    "       \n",
    "        area_element = placemark.find('.//kml:SimpleData[@name=\"area\"]', namespaces)\n",
    "        if area_element is not None:\n",
    "            area = area_element.text\n",
    "            areas.append(float(area))\n",
    "        else:\n",
    "           \n",
    "            areas.append(0)  \n",
    " \n",
    "        coordinate_element = placemark.find('.//kml:coordinates', namespaces)\n",
    "        if coordinate_element is not None and coordinate_element.text:\n",
    "            coordinate_string = coordinate_element.text\n",
    "            coordinate = parse_coordinates(coordinate_string)\n",
    "            coordinates.append(coordinate)\n",
    "        else:\n",
    "           \n",
    "            coordinates.append([])  \n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Area': areas,\n",
    "    'Coordinates': coordinates\n",
    "})\n",
    "\n",
    "\n",
    "csv_file_path = '/home/idisc02/Forest_Project_New/Forest_Monitoring/input/Verra_Projects/kml_files/05-Zhanjiang AR_Project boundary.csv'\n",
    "df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree as ET\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def parse_kml_to_csv(kml_file_path, csv_file_path):\n",
    "    try:\n",
    "        parser = ET.XMLParser(recover=True)  \n",
    "        with open(kml_file_path, 'rb') as file:\n",
    "            tree = ET.parse(file, parser=parser)  \n",
    "            root = tree.getroot()\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing the KML file: {e}\")\n",
    "        return\n",
    "\n",
    "    namespaces = {'kml': 'http://www.opengis.net/kml/2.2'}  \n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for placemark in root.findall('.//kml:Placemark', namespaces):\n",
    "        placemark_data = parse_placemark(placemark, namespaces)  \n",
    "        data.append(placemark_data)\n",
    "    \n",
    "    try:\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(csv_file_path, index=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving data to CSV: {e}\")\n",
    "\n",
    "def parse_placemark(placemark, namespaces):  \n",
    "    placemark_data = {}\n",
    "    for field in ['name',\"area_ha\"]:\n",
    "        element = placemark.find(f'.//kml:{field}', namespaces)  \n",
    "        if element is not None:\n",
    "            placemark_data[field] = element.text.strip()\n",
    "  \n",
    "    coordinates = placemark.find('.//kml:coordinates', namespaces)\n",
    "    if coordinates is not None:\n",
    "        placemark_data['coordinates'] = coordinates.text.strip()\n",
    "    parse_description(placemark_data)\n",
    "    return placemark_data\n",
    "\n",
    "def parse_description(placemark_data):\n",
    "    if 'description' in placemark_data:\n",
    "        soup = BeautifulSoup(placemark_data['description'], 'html.parser')\n",
    "        for tr in soup.find_all('tr')[1:]:\n",
    "            td_tags = tr.find_all('td')\n",
    "            if len(td_tags) == 2:\n",
    "                key = td_tags[0].text.strip()\n",
    "                value = td_tags[1].text.strip()\n",
    "                placemark_data[key] = value\n",
    "\n",
    "# Example usage\n",
    "kml_file_path = '/home/idisc02/Forest_Project_New/Forest_Monitoring/input/Verra_Projects/Project areas ID738.kml'\n",
    "csv_file_path = '/home/idisc02/Forest_Project_New/Forest_Monitoring/input/Verra_Projects/Project areas ID738.csv'\n",
    "parse_kml_to_csv(kml_file_path, csv_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "downgrade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
