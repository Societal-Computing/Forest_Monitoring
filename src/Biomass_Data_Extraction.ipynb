{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the biomass value from the dataset https://catalogue.ceda.ac.uk/uuid/bf535053562141c6bb7ad831f5998d77/\n",
    "1.Download data from to you pc https://catalogue.ceda.ac.uk/uuid/bf535053562141c6bb7ad831f5998d77/ atotal of 300gb space requirement for data for \"2015 to 2016\n",
    "\n",
    "2.Read Our polygon data and overlap which year raster files and extract the biomass values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Loading our polygons\n",
    "polygons_path = \"../input/new_df_reforestation_with_precipitation_biomass.geojson\"\n",
    "polygons_gdf = gpd.read_file(polygons_path)\n",
    "\n",
    "# Rasters downloaded from the https://catalogue.ceda.ac.uk/uuid/bf535053562141c6bb7ad831f5998d77/\n",
    "base_raster_dir = \"../dap.ceda.ac.uk/neodc/esacci/biomass/data/agb/maps/v5.0/geotiff\"\n",
    "\n",
    "# Years to process/extract data from (All available data to date)\n",
    "years = [2015, 2016, 2017, 2018, 2019, 2020]\n",
    "\n",
    "# Extracting the  raster precipitation values\n",
    "def extract_raster_values(raster_path, centroids):\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        transformed_centroids = centroids.to_crs(src.crs)\n",
    "        values = []\n",
    "        for point in transformed_centroids.geometry:\n",
    "            row, col = src.index(point.x, point.y)\n",
    "            if (0 <= row < src.height) and (0 <= col < src.width):\n",
    "                value = src.read(1)[row, col]\n",
    "                values.append(value)\n",
    "            else:\n",
    "                values.append(np.nan)\n",
    "        return values\n",
    "\n",
    "# processinng  GeoDataFrame in chunks due to its size and accepting a year parameter\n",
    "def process_in_chunks(gdf, chunk_size, year):\n",
    "    results_df = pd.DataFrame()\n",
    "    raster_dir = f\"{base_raster_dir}/{year}\"  \n",
    "\n",
    "    for start in range(0, len(gdf), chunk_size):\n",
    "        end = start + chunk_size\n",
    "        chunk = gdf.iloc[start:end]\n",
    "        if chunk.crs.is_geographic:\n",
    "            chunk = chunk.to_crs(\"EPSG:3395\")\n",
    "        chunk['centroid'] = chunk.geometry.centroid\n",
    "        \n",
    "        biomass_values = [0] * len(chunk)\n",
    "        \n",
    "        for raster_file in os.listdir(raster_dir):\n",
    "            if raster_file.endswith(\".tif\"):\n",
    "                raster_path = os.path.join(raster_dir, raster_file)\n",
    "                values = extract_raster_values(raster_path, chunk['centroid'])\n",
    "                biomass_values = [x + y if not np.isnan(y) else x for x, y in zip(biomass_values, values)]\n",
    "        \n",
    "        chunk[f'Biomass_{year}'] = biomass_values\n",
    "        chunk.drop(columns=['centroid'], inplace=True)\n",
    "        \n",
    "        results_df = pd.concat([results_df, chunk])\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "\n",
    "for year in years:\n",
    "    if year == years[0]:\n",
    "        final_gdf = process_in_chunks(polygons_gdf, 10000, year)\n",
    "    else:\n",
    "        temp_gdf = process_in_chunks(polygons_gdf, 10000, year)\n",
    "        final_gdf[f'Biomass_{year}'] = temp_gdf[f'Biomass_{year}']\n",
    "\n",
    "\n",
    "output_path = \"/home/idisc02/Forest_Monitoring/output/reforestation_with_precipitation_biomass_updated.geojson\"\n",
    "final_gdf.to_file(output_path, driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Climate data Extraction\n",
    "1.Download raster  data for precipitation to Pc from https://www.worldclim.org/\n",
    "2.Overlay polygons and extract rainfall from the centoid pixel of each polygon(Site)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from rasterio.mask import mask\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Updated geojson file of our data\n",
    "geojson_path = \"../updated_with_description_reforestation_projects_with_ndvi.geojson\"\n",
    "# Output folder for the processed data /Geojson file\n",
    "output_folder = \"../input/centroid_prec\"\n",
    "# The directory containing the .tif files  downloaded from https://catalogue.ceda.ac.uk/uuid/bf535053562141c6bb7ad831f5998d77/\n",
    "tif_folder = \"../climate_data_2.5m/\"\n",
    "\n",
    "gdf = gpd.read_file(geojson_path)\n",
    "\n",
    "# Checking for available .tif files in the directory\n",
    "tif_files = [f for f in os.listdir(tif_folder) if f.endswith(\".tif\")]\n",
    "if len(tif_files) == 0:\n",
    "    raise FileNotFoundError(\"No .tif files found in the directory.\")\n",
    "\n",
    "# Checking the CRS of the first .tif file and reproject if necessary\n",
    "tif_path = os.path.join(tif_folder, tif_files[0])\n",
    "with rasterio.open(tif_path) as src:\n",
    "    tif_crs = src.crs\n",
    "if gdf.crs != tif_crs:\n",
    "    gdf = gdf.to_crs(tif_crs)\n",
    "\n",
    "# Extracting Year of interest from our polygon \"Planting date feature\"\n",
    "def extract_year(date_str):\n",
    "    if pd.isna(date_str):\n",
    "        return np.nan\n",
    "    try:\n",
    "      \n",
    "        date_parsed = pd.to_datetime(date_str, errors='coerce')\n",
    "        if pd.notna(date_parsed):\n",
    "            return date_parsed.year\n",
    "    except ValueError:\n",
    "        pass  \n",
    "    \n",
    "   \n",
    "    if isinstance(date_str, str) and date_str.isdigit() and len(date_str) == 4:\n",
    "        return int(date_str)\n",
    "    \n",
    "    return np.nan\n",
    "\n",
    "gdf['planting_year'] = gdf['planting_date_reported'].apply(extract_year).astype('Int64')\n",
    "\n",
    "# Processing the data in chunks to  for resources management\n",
    "chunk_size = 5000\n",
    "\n",
    "\n",
    "tif_files_by_year = {}\n",
    "for tif_file in tif_files:\n",
    "    year_month = tif_file.split(\"_\")[-1].split(\".\")[0]\n",
    "    year, month = int(year_month.split(\"-\")[0]), int(year_month.split(\"-\")[1])\n",
    "    if year not in tif_files_by_year:\n",
    "        tif_files_by_year[year] = {}\n",
    "    tif_files_by_year[year][month] = tif_file\n",
    "\n",
    "\n",
    "for i in range(0, len(gdf), chunk_size):\n",
    "    gdf_chunk = gdf.iloc[i:i + chunk_size].copy()\n",
    "    precipitation_by_years_after_planting = {}\n",
    "\n",
    "    for idx, polygon in gdf_chunk.iterrows():\n",
    "        planting_year = polygon['planting_year']\n",
    "        if pd.isna(planting_year):\n",
    "            continue\n",
    "\n",
    "        precipitation_by_years_after_planting[idx] = {\n",
    "            'planting_year': 0, 'year_1': 0, 'year_2': 0, 'year_5': 0, \n",
    "            'has_data_planting': False, 'has_data_1': False, 'has_data_2': False, 'has_data_5': False\n",
    "        }\n",
    "\n",
    "        # Getting the centroid of the polygon to extract values for each polygon\n",
    "        centroid = polygon['geometry'].centroid\n",
    "        centroid_point = [(centroid.x, centroid.y)]  \n",
    "\n",
    "       # Process  data for each of the relevant years (planting year, year+1, year+2, year+5)\n",
    "        for year_offset in [0, 1, 2, 5]:\n",
    "            current_year = planting_year + year_offset\n",
    "            if current_year in tif_files_by_year:\n",
    "                total_precipitation_for_year = 0\n",
    "                has_valid_data = False\n",
    "\n",
    "                # Summing precipitation across all 12 months of each year\n",
    "                for month in range(1, 13):\n",
    "                    if month in tif_files_by_year[current_year]:\n",
    "                        tif_file = tif_files_by_year[current_year][month]\n",
    "                        tif_path = os.path.join(tif_folder, tif_file)\n",
    "\n",
    "                        try:\n",
    "                            with rasterio.open(tif_path) as src:\n",
    "                                # Getting the value at the centroid instead of the whole polygon\n",
    "                                for val in src.sample(centroid_point):\n",
    "                                    valid_data = val[0]\n",
    "                                    if not np.isnan(valid_data):\n",
    "                                        total_precipitation_for_year += valid_data\n",
    "                                        has_valid_data = True\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error processing {tif_file}: {e}\")\n",
    "\n",
    "                # Update the precipitation data dictionary based on the year offset\n",
    "                if year_offset == 0:\n",
    "                    precipitation_by_years_after_planting[idx]['planting_year'] = total_precipitation_for_year\n",
    "                    precipitation_by_years_after_planting[idx]['has_data_planting'] = has_valid_data\n",
    "                elif year_offset == 1:\n",
    "                    precipitation_by_years_after_planting[idx]['year_1'] = total_precipitation_for_year\n",
    "                    precipitation_by_years_after_planting[idx]['has_data_1'] = has_valid_data\n",
    "                elif year_offset == 2:\n",
    "                    precipitation_by_years_after_planting[idx]['year_2'] = total_precipitation_for_year\n",
    "                    precipitation_by_years_after_planting[idx]['has_data_2'] = has_valid_data\n",
    "                elif year_offset == 5:\n",
    "                    precipitation_by_years_after_planting[idx]['year_5'] = total_precipitation_for_year\n",
    "                    precipitation_by_years_after_planting[idx]['has_data_5'] = has_valid_data\n",
    "\n",
    "   # Updating the  the precipitation data dictionary based on the year offset\n",
    "    for idx, precip_data in precipitation_by_years_after_planting.items():\n",
    "        avg_precip_planting = precip_data['planting_year'] / 12 if precip_data['has_data_planting'] else np.nan\n",
    "        avg_precip_year_1 = precip_data['year_1'] / 12 if precip_data['has_data_1'] else np.nan\n",
    "        avg_precip_year_2 = precip_data['year_2'] / 12 if precip_data['has_data_2'] else np.nan\n",
    "        avg_precip_year_5 = precip_data['year_5'] / 12 if precip_data['has_data_5'] else np.nan\n",
    "\n",
    "        gdf_chunk.at[idx, \"avg_precip_planting_year\"] = avg_precip_planting\n",
    "        gdf_chunk.at[idx, \"avg_precip_1_year_after\"] = avg_precip_year_1\n",
    "        gdf_chunk.at[idx, \"avg_precip_2_years_after\"] = avg_precip_year_2\n",
    "        gdf_chunk.at[idx, \"avg_precip_5_years_after\"] = avg_precip_year_5\n",
    "\n",
    " # Saving each   chunking results to a new GeoJSON file\n",
    "    output_geojson_path = os.path.join(output_folder, f\"df_reforestation_chunk_{i}.geojson\")\n",
    "    gdf_chunk.to_file(output_geojson_path, driver=\"GeoJSON\")\n",
    "\n",
    "   \n",
    "    del gdf_chunk, precipitation_by_years_after_planting\n",
    "    gc.collect()\n",
    "\n",
    "    print(f\"Processed and saved chunk {i} to {output_geojson_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all precipitation chunks to a single file\n",
    "output_folder = \"../input/centroid_prec\"\n",
    "\n",
    "geojson_files = [os.path.join(output_folder, file) for file in os.listdir(output_folder) if file.endswith('.geojson')]\n",
    "\n",
    "gdfs = [gpd.read_file(file) for file in geojson_files]\n",
    "\n",
    "combined_gdf = gpd.GeoDataFrame(pd.concat(gdfs, ignore_index=True))\n",
    "\n",
    "combined_gdf.to_file(os.path.join(output_folder, \"df_reforestation_with_precipitation.geojson\"), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature Extraction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
