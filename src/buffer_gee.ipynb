{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import geemap\n",
    "import ee\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "\n",
    "# from google.colab import auth , drive\n",
    "# drive.mount('/content/drive') Only required if you are using google colab\n",
    "from helper_functions import  get_shadow_index_for_month, get_ndvi_for_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Authenticate()\n",
    "ee.Initialize(project='test-reforestation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Assuming this is the combined dataset and has  previously gee\n",
    "df = gpd.read_parquet(\"../midsave/consolidated_reforestation_projects.parquet\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = df.loc[:,['site_id_created', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.dropna(subset=['geometry'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 1000\n",
    "chunks = [gdf[i:i + chunk_size] for i in range(0, gdf.shape[0], chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S2 = ee.ImageCollection('COPERNICUS/S2_HARMONIZED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv_path = '../midsave/buffer_ndvi.csv'\n",
    "ndvi = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NDVI Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Processing chunk {i + 1}/{len(chunks)}\")\n",
    "\n",
    "    # Creating a 500-meter buffer around each feature\n",
    "    chunk['geometry'] = chunk['geometry'].buffer(500)\n",
    "\n",
    "    gdf_json_chunk = chunk.__geo_interface__\n",
    "\n",
    "    try:\n",
    "        fc_chunk = geemap.geojson_to_ee(gdf_json_chunk)\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting chunk {i + 1} to Earth Engine FeatureCollection: {e}\")\n",
    "        continue\n",
    "\n",
    "    ndvi_chunk = fc_chunk.map(lambda feature: get_ndvi_for_month(feature, S2))\n",
    "\n",
    "    temp_chunk_df = pd.DataFrame([feature['properties'] for feature in ndvi_chunk.getInfo()['features']])\n",
    "\n",
    "    # Appending to combined DataFrame\n",
    "    ndvi = pd.concat([ndvi, temp_chunk_df], ignore_index=True)\n",
    "\n",
    "buffer_ndvi_grouped = ndvi.groupby(['site_id_created'])['ndvi'].mean().reset_index()\n",
    "buffer_ndvi_grouped.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(\"All chunks processed, combined results saved to:\", output_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shadow Index Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_si = (gdf\n",
    "       .merge(df[['site_id_created', 'planting_date_reported', 'month', 'ndvi_monthly_mean']], on = 'site_id_created', how = 'left')\n",
    "       .reset_index(drop = True))\n",
    "gdf_si['planting_date_reported'] = gdf_si['planting_date_reported'].astype(int)\n",
    "gdf_si['month'] = gdf_si['month'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 1000\n",
    "chunks = [gdf_si[i:i + chunk_size] for i in range(0, gdf_si.shape[0], chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv_path = '../midsave/buffer_shadow_index.csv'\n",
    "shadow_index = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Processing chunk {i + 1}/{len(chunks)}\")\n",
    "\n",
    "    # Creating a 500-meter buffer around each feature\n",
    "    chunk['geometry'] = chunk['geometry'].buffer(500)\n",
    "\n",
    "    gdf_json_chunk = chunk.__geo_interface__\n",
    "\n",
    "    try:\n",
    "        fc_chunk = geemap.geojson_to_ee(gdf_json_chunk)\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting chunk {i + 1} to Earth Engine FeatureCollection: {e}\")\n",
    "        continue\n",
    "\n",
    "    shadow_index_chunk = fc_chunk.map(lambda feature: get_shadow_index_for_month(feature, S2))\n",
    "\n",
    "    temp_chunk_df = pd.DataFrame([feature['properties'] for feature in shadow_index_chunk.getInfo()['features']])\n",
    "\n",
    "    # Appending to combined DataFrame\n",
    "    shadow_index = pd.concat([shadow_index, temp_chunk_df], ignore_index=True)\n",
    "\n",
    "buffer_shadow_index_grouped = shadow_index.groupby(['site_id_created'])['shadow_index'].mean().reset_index()\n",
    "buffer_shadow_index_grouped.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(\"All chunks processed, combined results saved to:\", output_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = (df.merge(buffer_shadow_index_grouped, on = 'site_id_created', how = 'left')\n",
    "               .merge(buffer_ndvi_grouped, on = 'site_id_created', how = 'left'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.info()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
