{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the relevant data from pdfs and projects descriptions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading /Users/angela/Documents/Forest_Monitoring/midsave/project_descriptions/pd_goldstandard_12938.pdf with PyMuPDF: Failed to open file '/Users/angela/Documents/Forest_Monitoring/midsave/project_descriptions/pd_goldstandard_12938.pdf'.\n",
      "Skipping pd_goldstandard_12938.pdf: No text extracted.\n",
      "Error reading /Users/angela/Documents/Forest_Monitoring/midsave/project_descriptions/pd_goldstandard_12323.pdf with PyMuPDF: Failed to open file '/Users/angela/Documents/Forest_Monitoring/midsave/project_descriptions/pd_goldstandard_12323.pdf'.\n",
      "Skipping pd_goldstandard_12323.pdf: No text extracted.\n",
      "Skipping pd_goldstandard_3260.pdf: No text extracted.\n",
      "Error reading /Users/angela/Documents/Forest_Monitoring/midsave/project_descriptions/pd_goldstandard_3025.pdf with PyMuPDF: Failed to open file '/Users/angela/Documents/Forest_Monitoring/midsave/project_descriptions/pd_goldstandard_3025.pdf'.\n",
      "Skipping pd_goldstandard_3025.pdf: No text extracted.\n",
      "Error reading /Users/angela/Documents/Forest_Monitoring/midsave/project_descriptions/pd_goldstandard_12614.pdf with PyMuPDF: Failed to open file '/Users/angela/Documents/Forest_Monitoring/midsave/project_descriptions/pd_goldstandard_12614.pdf'.\n",
      "Skipping pd_goldstandard_12614.pdf: No text extracted.\n",
      "Extraction completed! Data saved to /Users/angela/Documents/Forest_Monitoring/midsave/project_descriptions/extracted_project_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from transformers import pipeline\n",
    "from helper_functions import extract_text_with_pymupdf ,extract_planting_date\n",
    "pdf_folder = \"/Users/angela/Documents/Forest_Monitoring/midsave/project_descriptions\"\n",
    "\n",
    "\n",
    "model_name = \"distilbert-base-cased-distilled-squad\"\n",
    "revision = \"626af31\"\n",
    "qa_pipeline = pipeline(\"question-answering\", model=model_name, revision=revision, framework=\"pt\")\n",
    "\n",
    "# Defining  the dates questions,\n",
    "questions = [\n",
    "    \"What is the planting date?\",\n",
    "    \"What is the project start date?\"\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for filename in os.listdir(pdf_folder):\n",
    "    if filename.endswith(\".pdf\") and (filename.startswith(\"pd_verra_\") or filename.startswith(\"pd_goldstandard_\")):\n",
    "        project_id = filename.split(\"_\")[-1].split(\".\")[0]\n",
    "        pdf_path = os.path.join(pdf_folder, filename)\n",
    "        text = extract_text_with_pymupdf(pdf_path)\n",
    "\n",
    "        if not text.strip():\n",
    "            print(f\"Skipping {filename}: No text extracted.\")\n",
    "            continue\n",
    "\n",
    "        project_data = {\"Project_ID\": project_id}\n",
    "\n",
    "        # Processing each question separately\n",
    "        for question in questions:\n",
    "            try:\n",
    "                result = qa_pipeline(question=question, context=text)\n",
    "                project_data[question] = result[\"answer\"]\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename} for question '{question}': {e}\")\n",
    "                project_data[question] = \"Error\"\n",
    "\n",
    "\n",
    "        results.append(project_data)\n",
    "\n",
    "# Saving  the results to a CSV file\n",
    "df = pd.DataFrame(results)\n",
    "output_csv = os.path.join(pdf_folder, \"../midsave/extracted_project_data.csv\")\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Extraction completed! Data saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading /Users/angela/Documents/Forest_Monitoring/midsave/project_descriptions/pd_goldstandard_12938.pdf with PyMuPDF: Failed to open file '/Users/angela/Documents/Forest_Monitoring/midsave/project_descriptions/pd_goldstandard_12938.pdf'.\n",
      "Skipping pd_goldstandard_12938.pdf: No text extracted.\n",
      "Error reading /Users/angela/Documents/Forest_Monitoring/midsave/project_descriptions/pd_goldstandard_12323.pdf with PyMuPDF: Failed to open file '/Users/angela/Documents/Forest_Monitoring/midsave/project_descriptions/pd_goldstandard_12323.pdf'.\n",
      "Skipping pd_goldstandard_12323.pdf: No text extracted.\n",
      "Skipping pd_goldstandard_3260.pdf: No text extracted.\n",
      "Error reading /Users/angela/Documents/Forest_Monitoring/midsave/project_descriptions/pd_goldstandard_3025.pdf with PyMuPDF: Failed to open file '/Users/angela/Documents/Forest_Monitoring/midsave/project_descriptions/pd_goldstandard_3025.pdf'.\n",
      "Skipping pd_goldstandard_3025.pdf: No text extracted.\n",
      "Error reading /Users/angela/Documents/Forest_Monitoring/midsave/project_descriptions/pd_goldstandard_12614.pdf with PyMuPDF: Failed to open file '/Users/angela/Documents/Forest_Monitoring/midsave/project_descriptions/pd_goldstandard_12614.pdf'.\n",
      "Skipping pd_goldstandard_12614.pdf: No text extracted.\n",
      "Extraction completed! Data saved to /Users/angela/Documents/Forest_Monitoring/midsave/project_descriptions/new_improvedbert_extracted_project_data.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "pdf_folder = \"/Users/angela/Documents/Forest_Monitoring/midsave/project_descriptions\"\n",
    "model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "bert_qa_pipeline = pipeline(\"question-answering\", model=model_name)\n",
    "questions = [\n",
    "  \n",
    "    \n",
    "    # # Species question\n",
    "   \"Which species were planted? Name each mentioned Species please\",\n",
    "    \n",
    "    # Purpose with multiple phrasings\n",
    "    \"What is the purpose  of the planting project?\",\n",
    "    \"What is the aim of the planting project?\",\n",
    "    \n",
    "    # # Community involvement\n",
    "    # \"Was there community involvement?\",\n",
    "    \n",
    "    # Area planted\n",
    "    \"What is the total area planted?\",\n",
    "    \n",
    "    # Tree count\n",
    "    \"How many trees were planted?\"\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "for filename in os.listdir(pdf_folder):\n",
    "     if filename.endswith(\".pdf\") and (filename.startswith(\"pd_verra_\") or filename.startswith(\"pd_goldstandard_\")):\n",
    "      \n",
    "        project_id = filename.split(\"_\")[-1].split(\".\")[0]\n",
    "        pdf_path = os.path.join(pdf_folder, filename)\n",
    "        text = extract_text_with_pymupdf(pdf_path)\n",
    "\n",
    "        if not text.strip():\n",
    "            print(f\"Skipping {filename}: No text extracted.\")\n",
    "            continue\n",
    "\n",
    "        project_data = {\"Project_ID\": project_id}\n",
    "        for question in questions:\n",
    "            try:\n",
    "                # Getting multiple possible answers with confidence scores\n",
    "                answers = bert_qa_pipeline(\n",
    "                    question=question,\n",
    "                    context=text,\n",
    "                    top_k=10,  # Get top 3 possible answers\n",
    "                    handle_impossible_answer=True\n",
    "                )\n",
    "                \n",
    "                # Selecting answer with highest confidence score\n",
    "                best_answer = max(answers, key=lambda x: x['score'])\n",
    "                \n",
    "                # Handling multiple purposes/reasons\n",
    "                if question == \"What is the purpose  of the planting project?\":\n",
    "                    all_purposes = [ans[\"answer\"] for ans in answers if ans[\"score\"] > 0.5]  # Adjust threshold as needed\n",
    "                    project_data[question] = \"; \".join(all_purposes)\n",
    "                else:\n",
    "                    project_data[question] = best_answer[\"answer\"]\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename} for question '{question}': {e}\")\n",
    "                project_data[question] = \"Error\"\n",
    "\n",
    "   \n",
    "\n",
    "        results.append(project_data)\n",
    "\n",
    "df_new2 = pd.DataFrame(results)\n",
    "output_csv = os.path.join(pdf_folder, \"new_improvedbert_extracted_project_data.csv\")\n",
    "df_new2.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Extraction completed! Data saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From manual annotation/text extraction results are saved to file\n",
    "\"/home/idisc02/Downloads/Manually_Filtered_extracted_text_sp_dates.csv\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "manual= pd.read_csv(\"../midsave/Manually_Filtered_extracted_text_sp_dates.csv\") \n",
    "\n",
    "\n",
    "manual.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../midsave/newest_consolidated_reforestation_projects_with_cicular.parquet\"\n",
    "\n",
    "\n",
    "reforestation_df= gpd.read_parquet(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Merge the extracted Columns/data to the original data\"\"\"\n",
    "reforestation_project_gdf = reforestation_df.merge(\n",
    "   manual[['Project_ID', 'Which species were planted? Name each mentioned Species please_y','What is the planting date?']],  \n",
    "    left_on='project_id_reported', \n",
    "    right_on='Project_ID',\n",
    "    how='left'  \n",
    ")\n",
    "\n",
    "\n",
    "reforestation_project_gdf = reforestation_project_gdf.drop(columns=['Project_ID'])\n",
    "\n",
    "reforestation_project_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Cleaning the data\"\"\"\n",
    "reforestation_project_gdf = reforestation_project_gdf.replace('\\n', '', regex=True)\n",
    "reforestation_project_gdf = reforestation_project_gdf.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "reforestation_project_gdf['What is the planting date?'] = pd.to_datetime(\n",
    "    reforestation_project_gdf['What is the planting date?'],\n",
    "    format='mixed',  \n",
    "    errors='coerce' \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filtered_gdf = reforestation_project_gdf[reforestation_project_gdf['What is the planting date?'].notna()]\n",
    "\n",
    "filtered_gdf = filtered_gdf.rename(columns={\"What is the planting date?\": \"planting_date_derived\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" For projects without pdfs we extract the dates and other variables from descrition\"\"\"\n",
    "others_data=reforestation_project_gdf[reforestation_project_gdf['What is the planting date?'].isna()]\n",
    "others_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction From descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "others_data[\"planting_date_derived\"] = others_data[\"project_description_reported\"].apply(extract_planting_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "bert_qa_pipeline = pipeline(\"question-answering\", model=model_name)\n",
    "\n",
    "\n",
    "questions = [\n",
    "    \"Which species were planted? Name each mentioned Species please\",\n",
    "    \"What is the purpose of the planting project?\",\n",
    "    \"What is the aim of the planting project?\",\n",
    "    \"What is the total area planted?\",\n",
    "    \"How many trees were planted?\"\n",
    "]\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "for _, row in others_data.iterrows():\n",
    "    project_id = row[\"Project_ID\"]\n",
    "    context = row[\"project_description_reported\"]\n",
    "\n",
    "    project_data = {\"Project_ID\": project_id}\n",
    "    for question in questions:\n",
    "        try:\n",
    "            # Getting multiple possible answers with confidence scores\n",
    "            answers = bert_qa_pipeline(\n",
    "                question=question,\n",
    "                context=context,\n",
    "                top_k=10,  \n",
    "                handle_impossible_answer=True\n",
    "            )\n",
    "\n",
    "            # Selecting the answer with the highest confidence score\n",
    "            best_answer = max(answers, key=lambda x: x['score'])\n",
    "\n",
    "            # Handling the multiple purposes/reasons\n",
    "            if question == \"What is the purpose of the planting project?\":\n",
    "                all_purposes = [ans[\"answer\"] for ans in answers if ans[\"score\"] > 0.5]  # Adjust threshold as needed\n",
    "                project_data[question] = \"; \".join(all_purposes)\n",
    "            else:\n",
    "                project_data[question] = best_answer[\"answer\"]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing Project_ID {project_id} for question '{question}': {e}\")\n",
    "            project_data[question] = \"Error\"\n",
    "\n",
    "    results.append(project_data)\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
