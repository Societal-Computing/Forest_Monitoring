{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = gpd.read_file('/home/idisc02/Forest_Monitoring/src/df_reforestation.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking for nested Polygons and creating column \"Nested_in\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects['Nested_in'] = [[] for _ in range(len(projects))]\n",
    "\n",
    "\n",
    "filtered_projects=projects\n",
    "\n",
    "possible_matches = gpd.sjoin(filtered_projects, filtered_projects, how='left', op='within')\n",
    "\n",
    "possible_matches = possible_matches[possible_matches.index != possible_matches.index_right]\n",
    "\n",
    "\n",
    "nested_in_mapping = possible_matches.groupby(possible_matches.index)['created_site_ids_right'].apply(list)\n",
    "\n",
    "\n",
    "for index, nested_in in nested_in_mapping.items():\n",
    "    filtered_projects.at[index, 'Nested_in'] = nested_in\n",
    "\n",
    "\n",
    "filtered_projects['Nested_in'] = filtered_projects['Nested_in'].apply(lambda x: ', '.join(map(str, x)) if x else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering out all Nesting polygons with site_sqkm>=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "site_sqkm_lookup = filtered_projects.set_index('created_site_ids')['site_sqkm'].to_dict()\n",
    "\n",
    "\n",
    "nested_ids = filtered_projects['Nested_in'].dropna().apply(lambda x: x.split(', ')).explode().unique()\n",
    "\n",
    "\n",
    "nested_ids_set = set(nested_ids)\n",
    "\n",
    "\n",
    "rows_to_drop = filtered_projects[\n",
    "    filtered_projects['created_site_ids'].isin(nested_ids_set) & \n",
    "    (filtered_projects['site_sqkm'] >= 100)\n",
    "].index\n",
    "\n",
    "\n",
    "filtered_projects = filtered_projects.drop(index=rows_to_drop).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Multiple nesting polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "site_sqkm_lookup = filtered_projects.set_index('created_site_ids')['site_sqkm'].to_dict()\n",
    "\n",
    "\n",
    "single_or_no_nested_rows = filtered_projects[\n",
    "    filtered_projects['Nested_in'].apply(lambda x: isinstance(x, str) and len(x.split(', ')) == 1 or pd.isna(x))\n",
    "]\n",
    "\n",
    "print(f\"Rows with single or no 'Nested_in': {single_or_no_nested_rows.shape[0]}\")\n",
    "\n",
    "multi_nested_rows = filtered_projects[\n",
    "    filtered_projects['Nested_in'].apply(lambda x: isinstance(x, str) and len(x.split(', ')) > 1)\n",
    "]\n",
    "\n",
    "\n",
    "multi_nested_ids = multi_nested_rows['Nested_in'].str.split(', ').explode().unique()\n",
    "\n",
    "print(f\"Rows with multiple values in 'Nested_in': {multi_nested_rows.shape[0]}\")\n",
    "\n",
    "relevant_rows = filtered_projects[\n",
    "    filtered_projects['created_site_ids'].isin(multi_nested_ids)\n",
    "]\n",
    "\n",
    "\n",
    "max_site_sqkm_rows = relevant_rows.groupby('created_site_ids').apply(\n",
    "    lambda x: x.loc[x['site_sqkm'].idxmax()]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "\n",
    "rows_to_keep_from_multi_nested = multi_nested_rows.merge(\n",
    "    max_site_sqkm_rows[['created_site_ids']], \n",
    "    on='created_site_ids'\n",
    ").drop_duplicates()\n",
    "\n",
    "print(f\"Rows to keep from multi-nested rows: {rows_to_keep_from_multi_nested.shape[0]}\")\n",
    "\n",
    "filtered_projects = pd.concat([single_or_no_nested_rows, rows_to_keep_from_multi_nested]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "print(f\"Final number of rows: {filtered_projects.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_with_lists = [col for col in filtered_projects.columns if col != 'geometry' and filtered_projects[col].apply(lambda x: isinstance(x, list)).any()]\n",
    "\n",
    "\n",
    "for col in columns_with_lists:\n",
    "    filtered_projects[col] = filtered_projects[col].apply(lambda x: str(x) if isinstance(x, list) else x)\n",
    "\n",
    "output_path = '/home/idisc02/Forest_Monitoring/new_filtered_nested_mult.gpkg'\n",
    "\n",
    "\n",
    "filtered_projects.to_file(output_path, driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intersecting Polgons checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_projects = gpd.GeoDataFrame(filtered_projects, geometry='geometry')\n",
    "\n",
    "\n",
    "spatial_index = filtered_projects.sindex\n",
    "\n",
    "filtered_projects['Intersecting_with'] = None\n",
    "\n",
    "\n",
    "intersections_dict = {i: [] for i in filtered_projects.index}\n",
    "\n",
    "\n",
    "def find_intersections(row):\n",
    "    global num_intersecting_pairs\n",
    "    possible_matches_index = list(spatial_index.intersection(row.geometry.bounds))\n",
    "    intersecting_ids = []\n",
    "    \n",
    "    for j in possible_matches_index:\n",
    "        if row.name >= j:\n",
    "            continue  \n",
    "        \n",
    "        other_row = filtered_projects.iloc[j]\n",
    "        if row.geometry.intersects(other_row.geometry):\n",
    "            intersecting_ids.append(other_row['created_site_ids'])\n",
    "            intersections_dict[j].append(row['created_site_ids'])\n",
    "            num_intersecting_pairs += 1\n",
    "    return intersecting_ids\n",
    "\n",
    "\n",
    "filtered_projects['Intersecting_with'] = filtered_projects.apply(find_intersections, axis=1)\n",
    "\n",
    "\n",
    "for idx, intersecting_ids in enumerate(filtered_projects['Intersecting_with']):\n",
    "    intersections_dict[idx] += intersecting_ids\n",
    "\n",
    "\n",
    "filtered_projects['Intersecting_with'] = filtered_projects['Intersecting_with'].apply(lambda x: ', '.join(x) if x else None)\n",
    "\n",
    "print(filtered_projects[['created_site_ids', 'Intersecting_with']].head())\n",
    "print(f\"Number of intersecting pairs: {num_intersecting_pairs}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "downgrade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
