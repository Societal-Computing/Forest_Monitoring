{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde007a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from bs4 import BeautifulSoup\n",
    "from shapely.ops import transform\n",
    "from shapely.geometry import MultiPolygon, MultiLineString, MultiPoint, Polygon, LineString, Point\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from random import uniform\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab662125",
   "metadata": {},
   "source": [
    "### Important functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27290db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmz_to_kml(content):\n",
    "    try:\n",
    "        with zipfile.ZipFile(BytesIO(content)) as kmz:\n",
    "            with kmz.open(next(f for f in kmz.namelist() if f.endswith('.kml'))) as kml_file:\n",
    "                return kml_file.read().decode('utf-8')\n",
    "    except zipfile.BadZipFile:\n",
    "        return content.decode('utf-8')\n",
    "\n",
    "# Function to fetch and parse KML file\n",
    "def fetch_kml(uri):\n",
    "    response = requests.get(uri)\n",
    "    if response.status_code == 200:\n",
    "        return response.content\n",
    "    else:\n",
    "        print(f\"Failed to download KML file from {uri}\")\n",
    "        return None\n",
    "\n",
    "# Function to parse KML and convert to geometries\n",
    "def parse_kml(content):\n",
    "    soup = BeautifulSoup(content, 'xml')\n",
    "    geometries = []\n",
    "\n",
    "    # Find all MultiGeometry elements, which can host multiple Polygons\n",
    "    for multi_geom in soup.find_all('MultiGeometry'):\n",
    "        polygons = []\n",
    "        linestrings = []\n",
    "        points = []\n",
    "        for polygon in multi_geom.find_all('Polygon'):\n",
    "            if polygon.find('coordinates').string == None:\n",
    "                polygons.append(Polygon())\n",
    "                continue\n",
    "            coords = polygon.find('coordinates').string.strip().split()\n",
    "            c_points = [tuple(map(float, c.split(','))) for c in coords]\n",
    "            polygons.append(Polygon(c_points))\n",
    "        for linestring in multi_geom.find_all('LineString'):\n",
    "            if linestring.find('coordinates').string == None:\n",
    "                linestrings.append(LineString())\n",
    "                continue\n",
    "            coords = linestring.find('coordinates').string.strip().split()\n",
    "            c_points = [tuple(map(float, c.split(','))) for c in coords]\n",
    "            if len(c_points) != 1:\n",
    "                linestrings.append(LineString(c_points))\n",
    "            else:\n",
    "                geometries.append(Point(c_points))\n",
    "        for point in multi_geom.find_all('Point'):\n",
    "            if point.find('coordinates').string == None:\n",
    "                points.append(Point())\n",
    "                continue\n",
    "            coords = point.find('coordinates').string.strip().split()\n",
    "            c_points = [tuple(map(float, c.split(','))) for c in coords]\n",
    "            points.append(Point(c_points))\n",
    "        if polygons:\n",
    "            geometries.append(MultiPolygon(polygons))\n",
    "        if linestrings:\n",
    "            geometries.append(MultiLineString(linestrings))\n",
    "        if points:\n",
    "            geometries.append(MultiPoint(points))\n",
    "\n",
    "    # Also check for geometries that are not part of MultiGeometry\n",
    "    # Check for Polygons\n",
    "    for polygon in soup.find_all('Polygon'):\n",
    "        if polygon.parent.name != 'MultiGeometry':\n",
    "            if polygon.find('coordinates').string == None:\n",
    "                geometries.append(Polygon())\n",
    "                continue\n",
    "            coords = polygon.find('coordinates').string.strip().split()\n",
    "            c_points = [tuple(map(float, c.split(','))) for c in coords]\n",
    "            geometries.append(Polygon(c_points))\n",
    "\n",
    "    # Check for LineStrings\n",
    "    for linestring in soup.find_all('LineString'):\n",
    "        if linestring.parent.name != 'MultiGeometry':\n",
    "            if linestring.find('coordinates').string == None:\n",
    "                geometries.append(LineString())\n",
    "                continue\n",
    "            coords = linestring.find('coordinates').string.strip().split()\n",
    "            c_points = [tuple(map(float, c.split(','))) for c in coords]\n",
    "            if len(c_points) != 1:\n",
    "                geometries.append(LineString(c_points))\n",
    "            else:\n",
    "                geometries.append(Point(c_points))\n",
    "\n",
    "    # Check for Points\n",
    "    for point in soup.find_all('Point'):\n",
    "        if point.parent.name != 'MultiGeometry':\n",
    "            if point.find('coordinates').string == None:\n",
    "                geometries.append(Point())\n",
    "                continue\n",
    "            coords = point.find('coordinates').string.strip().split()\n",
    "            c_points = [tuple(map(float, c.split(','))) for c in coords]\n",
    "            geometries.append(Point(c_points))\n",
    "\n",
    "    return geometries\n",
    "\n",
    "# Main processing\n",
    "def process_kml_uris(kml_uris):\n",
    "    all_geometries = []\n",
    "    for uri in kml_uris:\n",
    "        uri_content = fetch_kml(uri)\n",
    "        if uri_content:\n",
    "            kml_content = kmz_to_kml(uri_content)\n",
    "            geometries = parse_kml(kml_content)\n",
    "            all_geometries.extend(geometries)\n",
    "    return all_geometries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd1a4d7",
   "metadata": {},
   "source": [
    "### Read project list\n",
    "\n",
    "Project lists were acquired from the Verra registry at July 8th and 9th, 2024 by using the export to csv functionality for bulk download:\n",
    "\n",
    "- Verified Carbon Standard (VCS): https://registry.verra.org/app/search/VCS/All%20Projects\n",
    "- Climate, Community & Biodiversity Standards (CCB): https://registry.verra.org/app/search/CCB/All%20Projects\n",
    "- Sustainable Development Verified Impact Standard (VISta): https://registry.verra.org/app/search/SDVISTA/All%20Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970b9cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_vcs = pd.read_csv('/Users/tillkoebe/Documents/GitHub/Forest_Monitoring/input/Verra/allprojects_vcs.csv')\n",
    "projects_ccb = pd.read_csv('/Users/tillkoebe/Documents/GitHub/Forest_Monitoring/input/Verra/allprojects_ccb.csv')\n",
    "projects_vista = pd.read_csv('/Users/tillkoebe/Documents/GitHub/Forest_Monitoring/input/Verra/allprojects_vista.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411525ec-00f0-4299-b2f8-01954388e9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(projects_vcs.shape, projects_ccb.shape, projects_vista.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393cd55d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "projects_vcs.dropna(subset = 'AFOLU Activities', inplace = True)\n",
    "projects_ccb.dropna(subset = 'CCB Project Type', inplace = True)\n",
    "projects_vista.dropna(subset = 'Project Type', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e770ea5a-d09c-46fe-8f8f-302f8b1623a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(projects_vcs.shape, projects_ccb.shape, projects_vista.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5f904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_list_vcs = projects_vcs[projects_vcs['AFOLU Activities'].str.contains(\"ARR\")].ID.tolist()\n",
    "project_list_ccb = projects_ccb[projects_ccb['CCB Project Type'].str.contains(\"Afforestation, Reforestation and Revegetation\")].ID.tolist()\n",
    "project_list_vista = projects_vista[projects_vista['Project Type'].str.contains(\"Agriculture Forestry and Other Land Use\")].ID.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b86f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_list = list(set(project_list_vcs + project_list_ccb + project_list_vista))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186f8926-aa27-475e-8031-38a6e5879f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(project_list), len(project_list_vcs), len(project_list_ccb), len(project_list_vista))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810be2e8",
   "metadata": {},
   "source": [
    "### Extract geometries per project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3291881-b996-4891-9056-317ef5fe4b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_gdf = pd.DataFrame()\n",
    "no_geom_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf32755",
   "metadata": {},
   "outputs": [],
   "source": [
    "for project_id in tqdm(project_list):\n",
    "\n",
    "    try:\n",
    "        response = requests.get(f'https://registry.verra.org/uiapi/resource/resourceSummary/{project_id}')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error with project {project_id}: {e}\")\n",
    "        continue\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extract KML URIs\n",
    "        kml_uris = []\n",
    "        for group in data.get('documentGroups', []):\n",
    "            for document in group.get('documents', []):\n",
    "                if document['documentType'].lower() == 'kml file' or document['documentName'].endswith('.kml'):\n",
    "                    kml_uris.append(document['uri'])\n",
    "        if kml_uris:\n",
    "            kml_uris = list(set(kml_uris))\n",
    "            try:\n",
    "                # Process the KML URIs to get geometries\n",
    "                geometries = process_kml_uris(kml_uris)\n",
    "    \n",
    "            except Exception as e:\n",
    "                print(f\"Error querying the geometry of project {project_id}: {e}\")\n",
    "                continue\n",
    "        else:\n",
    "            no_geom_list.append(project_id)\n",
    "            print(f'No geometries available for project: {project_id}')\n",
    "\n",
    "        # Convert geometries to GeoPandas DataFrame\n",
    "        temp = gpd.GeoDataFrame(geometry=geometries)\n",
    "        \n",
    "        # Assign CRS\n",
    "        if abs(temp.geometry.centroid.y).max() > 180:\n",
    "            temp = temp.set_crs(3857).to_crs(4326)\n",
    "        else:\n",
    "            temp = temp.set_crs(4326)\n",
    "\n",
    "        # Explode MultiPolygons into individual Polygons\n",
    "        temp = temp.explode(index_parts=False)\n",
    "        \n",
    "        # 3D to 2D geometries\n",
    "        temp['geometry'] = temp['geometry'].apply(lambda geometry: transform(lambda x, y, z=None: (x, y), geometry))\n",
    "        \n",
    "        # Assign identifiers\n",
    "        temp['project_id'] = project_id\n",
    "        if data['description']:\n",
    "            temp['project_description'] = data['description']\n",
    "        else:\n",
    "            temp['project_description'] = None\n",
    "        temp = temp.reset_index(drop = True).reset_index().rename(columns={'index': 'site_id'})\n",
    "        \n",
    "        # Add project to output\n",
    "        project_gdf = pd.concat([project_gdf, temp], ignore_index=True)\n",
    "        \n",
    "        # Delay to avoid excess request responses\n",
    "        time.sleep(uniform(0, 2.0))\n",
    "        \n",
    "    else:\n",
    "        print(f\"Request failed with status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0acbcb-7304-4bb0-a4eb-db0719b35744",
   "metadata": {},
   "source": [
    "Check which project ids are not included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b160cf-ae0f-425e-9e0d-877368341335",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(project_list) - set(project_gdf['project_id']) - set(no_geom_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8924737d-f8ce-4b8a-b798-bca345f27d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_list = set(project_list) - set(project_gdf['project_id']) - set(no_geom_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae962882-12a2-4997-a521-6a2c55275d4d",
   "metadata": {},
   "source": [
    "!! Important: Re-run function above to ensure all projects have been queried !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff0b0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_gdf.project_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63574c9b-a2b8-4944-a2c1-e761f4b28e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_gdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5462d17-ffbe-483e-b318-501f8cd36cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_gdf['geometry'] = project_gdf['geometry'].make_valid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03e08c6-71a6-4754-8fca-aa0e33c2703e",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_gdf = project_gdf.explode(index_parts=False).explode(index_parts=False).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8d1e8b-4908-4a7f-8f93-d48b576b105a",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_gdf['geometry'] = project_gdf['geometry'].apply(\n",
    "    lambda geom: Polygon(list(geom.coords) + [geom.coords[0]]) if isinstance(geom, LineString) and not geom.is_closed and len(geom.coords) > 0 else\n",
    "                 Polygon(geom.coords) if isinstance(geom, LineString) and geom.is_closed else\n",
    "                 geom\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d017eaca-1092-43d4-8a4e-04ae3d9a7a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_gdf['geometry'] = project_gdf['geometry'].make_valid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bf10d7-e64c-4756-b0c6-ef54731251d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_gdf['sites_sqkm'] = project_gdf.to_crs(3857).area/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f157c57c-ee44-4a7f-a031-e8e95251b9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_gdf.sites_sqkm.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6c9aa3-504b-405a-876c-9714d4718134",
   "metadata": {},
   "source": [
    "Add project-level metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c1f742-2376-480b-8e12-95737a1fdf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_df = (pd.concat([projects_vcs[['ID', 'Name', 'Status', 'Country/Area']], \n",
    "                         projects_ccb[['ID', 'Name', 'Status', 'Country/Area']], \n",
    "                         projects_vista[['ID', 'Name', 'Status', 'Country/Area']]])\n",
    "               .drop_duplicates(subset = 'ID')\n",
    "               .rename(columns = {'ID':'project_id', 'Name':'project_name', 'Status':'status_reported', 'Country/Area':'country_reported'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712f0c77-c78b-455a-a12d-597d8e63807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_gdf = project_gdf.merge(projects_df, on = 'project_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49565c6e-a80b-45ff-9706-4506129a7610",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_gdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caefd3c6-465e-4a70-9258-cbe182135a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_gdf.to_file(\"/Users/tillkoebe/Documents/GitHub/Forest_Monitoring/input/Verra/verra_sites.gpkg\", driver=\"GPKG\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
